{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3999276",
   "metadata": {},
   "source": [
    "# Document Understanding Solution - Relationship Extraction\n",
    "\n",
    "Relation Extraction (RE) is the task of extracting semantic relationships from text, which usually occur between two or more entities. In this notebook,  we demonstrate two use cases of Relation Extraction:\n",
    "\n",
    "1. How to fine-tune a pre-trained Transformer model on a custom dataset, and then run inference on the fine-tuned model.\n",
    "2. How to run [SageMaker Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html) (a hyperparameter optimization procedure) to find the best model compared with the model fine-tuned in point 1. The performance of the optimal model and model fine-tuned in point 1 is evaluated on a hold-out test data. \n",
    "\n",
    "**Note**: When running this notebook on SageMaker Studio, you should make\n",
    "sure the `PyTorch 1.10 Python 3.8 CPU Optimized` image/kernel is used. When\n",
    "running this notebook on SageMaker Notebook Instance, you should make\n",
    "sure the 'sagemaker-soln' kernel is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3611eab5",
   "metadata": {},
   "source": [
    "This solution relies on a config file to run the provisioned AWS resources. Run the cell below to generate that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f0ba22e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import json\n",
    "\n",
    "client = boto3.client('servicecatalog')\n",
    "cwd = os.getcwd().split('/')\n",
    "i= cwd.index('S3Downloads')\n",
    "pp_name = cwd[i + 1]\n",
    "pp = client.describe_provisioned_product(Name=pp_name)\n",
    "record_id = pp['ProvisionedProductDetail']['LastSuccessfulProvisioningRecordId']\n",
    "record = client.describe_record(Id=record_id)\n",
    "\n",
    "keys = [ x['OutputKey'] for x in record['RecordOutputs'] if 'OutputKey' in x and 'OutputValue' in x]\n",
    "values = [ x['OutputValue'] for x in record['RecordOutputs'] if 'OutputKey' in x and 'OutputValue' in x]\n",
    "stack_output = dict(zip(keys, values))\n",
    "\n",
    "with open(f'/root/S3Downloads/{pp_name}/stack_outputs.json', 'w') as f:\n",
    "    json.dump(stack_output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926fe1a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Install required package to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "490d7cac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///root/S3Downloads/jumpstart-prod-doc_ewrtgp/notebooks/../wheelhouse\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.8/site-packages (2.168.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.0.6)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.4.1)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.26.162)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.8/site-packages (from sagemaker) (2.5.1)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.17.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.22.2)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.11.2)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (3.19.4)\n",
      "Requirement already satisfied: PyYAML==6.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (6.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (8.0.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.5.6)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.162 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.29.162)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.7.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (60.9.3)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: black in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (22.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (3.0.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (5.12.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (1.3.10)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2021.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.8/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.30.0,>=1.29.162->boto3<2.0,>=1.26.131->sagemaker) (1.26.8)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (4.1.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (8.0.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (0.4.3)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (0.9.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (4.9.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (19.0.0)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker ipywidgets --find-links file://$PWD/../wheelhouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6087297b-f67d-41eb-acb8-b4172bdf52af",
   "metadata": {},
   "source": [
    "## 1. Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b3fce9",
   "metadata": {},
   "source": [
    "We start by importing a variety of packages that will be used throughout\n",
    "the notebook. One of the most important packages is the Amazon SageMaker\n",
    "Python SDK (i.e. `import sagemaker`). We also import modules from our own\n",
    "custom (and editable) package that can be found at `../package`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ea4b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from pathlib import Path\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../package')\n",
    "from package import config, utils\n",
    "\n",
    "aws_role = config.IAM_ROLE\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c79e8-cc68-4906-91e2-2792377b0de6",
   "metadata": {},
   "source": [
    "## 2. Finetune the pre-trained model on a custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d35a09-ac2d-4204-bb4c-355b1c61c2c6",
   "metadata": {},
   "source": [
    "This is a Relationship Extraction model built on a [Bert-base-uncased](https://huggingface.co/bert-base-uncased) using transformers from the [transformers](https://huggingface.co/transformers/) library. \n",
    "\n",
    "The model for fine-tuning attaches a linear classification layer that takes a pair of token embeddings outputted by the Text Embedding model\n",
    "and initializes the layer parameters to random values. The fine-tuning step fine-tunes \n",
    "all the model parameters to minimize prediction error on the input data and returns the fine-tuned model. The Text Embedding model we use in this demonstartion is [Bert-base-uncased](https://huggingface.co/bert-base-uncased) from the [transformers](https://huggingface.co/transformers/) library. The dataset we fine-tune the model is [SemEval-2010 Task 8](https://aclanthology.org/S10-1006/). The SemEval-2 Task 8 is a dataset for multi-way classification of mutually exclusive semantic relations between pairs of nominals.\n",
    "\n",
    "\n",
    "The model returned by fine-tuning can be further deployed for inference. Below are the instructions \n",
    "for how the training data should be formatted for input to the model. \n",
    "\n",
    "- **Input:**  A directory containing a `txt` format file.\n",
    "    - Each observation contains three components, text, semantic relation label, and comment (optional), each of which takes a line in the `txt` format file. Observations are separated by an empty line. For each observation, there are markers highlighting the two terms in the text and their semantic relation label in the line below.\n",
    "- **Output:** A trained model that can be deployed for inference. \n",
    " \n",
    "Below is an example of `txt` format file. Note. Desipte of the same semantic relation label, pairs of entities with different order relations are counted as different labels. For an example, `Component-Whole(e2,e1)` and `Component-Whole(e1,e2)` are different semantic relation labels. The data for training and validation will be downloaded into directory `../data/semeval2010t8` in the following section.\n",
    "\n",
    "|   |\n",
    "|--- |\n",
    "|1  \"The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\"|\n",
    "|Component-Whole(e2,e1)|\n",
    "|Comment: Not a collection: there is structure here, organisation.|\n",
    "||\n",
    "|2  \"The <e1>child</e1> was carefully wrapped and bound into the <e2>cradle</e2> by means of a cord.\"|\n",
    "|Other|\n",
    "|Comment: NA|\n",
    "| |\n",
    "|3  \"The <e1>author</e1> of a keygen uses a <e2>disassembler</e2> to look at the raw assembly code.\"|\n",
    "|Instrument-Agency(e2,e1)|\n",
    "|Comment: NA|\n",
    "||\n",
    "|...   |\n",
    " \n",
    "\n",
    "\n",
    "Citation:\n",
    "@inproceedings{hendrickx-etal-2010-semeval,\n",
    "    title = \"{S}em{E}val-2010 Task 8: Multi-Way Classification of Semantic Relations between Pairs of Nominals\",\n",
    "    author = \"Hendrickx, Iris  and\n",
    "      Kim, Su Nam  and\n",
    "      Kozareva, Zornitsa  and\n",
    "      Nakov, Preslav  and\n",
    "      {\\'O} S{\\'e}aghdha, Diarmuid  and\n",
    "      Pad{\\'o}, Sebastian  and\n",
    "      Pennacchiotti, Marco  and\n",
    "      Romano, Lorenza  and\n",
    "      Szpakowicz, Stan\",\n",
    "    booktitle = \"Proceedings of the 5th International Workshop on Semantic Evaluation\",\n",
    "    month = jul,\n",
    "    year = \"2010\",\n",
    "    address = \"Uppsala, Sweden\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://www.aclweb.org/anthology/S10-1006\",\n",
    "    pages = \"33--38\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f647f-2e0b-41f3-b808-d116a472ecb4",
   "metadata": {},
   "source": [
    "### 2.1. Download, preprocess, and upload the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b61e5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-solutions-prod-us-east-1/0.2.0/Document-understanding/3.0.3/artifacts/data/semeval2010t8/test/test.txt to ../data/semeval2010t8/test/test.txt\n",
      "download: s3://sagemaker-solutions-prod-us-east-1/0.2.0/Document-understanding/3.0.3/artifacts/data/semeval2010t8/train/train.txt to ../data/semeval2010t8/train/train.txt\n",
      "download: s3://sagemaker-solutions-prod-us-east-1/0.2.0/Document-understanding/3.0.3/artifacts/data/semeval2010t8/validation/validation.txt to ../data/semeval2010t8/validation/validation.txt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $config.SOURCE_S3_PATH/artifacts/data/semeval2010t8/ ../data/semeval2010t8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9f3064-7b2f-4d78-b542-a1fb80338bc1",
   "metadata": {},
   "source": [
    "The dataset has been partitioned into `train.txt`, `validation.txt`, and `test.txt` data. Thus we don't need split the train data as what we do in previous notebooks. The`train.txt` and `validation.txt` will be used as training and validation data. The `test.txt` will be used as hold-out test data to evaluate model performance with / without hyperparameter optimization. Next, we upload them into S3 path which will be used as input for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff7193d-26a8-4e7a-97d0-a65c78a9211a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "bucket = config.S3_BUCKET\n",
    "prefix = \"RE\"\n",
    "\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"train/train.txt\")\n",
    ").upload_file(\"../data/semeval2010t8/train/train.txt\")\n",
    "\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"validation/validation.txt\")\n",
    ").upload_file(\"../data/semeval2010t8/validation/validation.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09132c77-f34d-4c7f-b4c2-0251253f9d98",
   "metadata": {},
   "source": [
    "### 2.2. Set Training parameters\n",
    "\n",
    "Now that we are done with all the setup that is needed, we are ready to fine-tune our relation extraction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91465a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"pretrained-model\": \"bert-base-uncased\",\n",
    "    \"learning-rate\": 0.0002,\n",
    "    \"max-epoch\": 2,\n",
    "    \"weight-decay\": 0.01,\n",
    "    \"batch-size\": 8,\n",
    "    \"accumulate-grad-batches\": 1,\n",
    "    \"gradient-clip-val\": 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ad5b2-be6f-4c5c-af71-53a056122ad2",
   "metadata": {},
   "source": [
    "### 3.2. Fine-tuning without hyperparameter optimization\n",
    "\n",
    "We use the PyTorch from the Amazon SageMaker Python SDK. The entry script is located under `../containers/relationship_extraction/entry_point.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf0332e8-355a-4eba-8def-45f3ee1b1ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_job_name = f\"{config.SOLUTION_PREFIX}-re-finetune\"\n",
    "\n",
    "train_instance_type = config.TRAINING_INSTANCE_TYPE\n",
    "#train_instance_type = 'ml.g4dn.4xlarge'\n",
    "\n",
    "re_estimator = PyTorch(\n",
    "    framework_version='1.10.0',\n",
    "    py_version='py38',\n",
    "    entry_point='entry_point.py',\n",
    "    source_dir='../containers/relationship_extraction',\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=aws_role,\n",
    "    instance_count=1,\n",
    "    instance_type=train_instance_type,\n",
    "    output_path=f\"s3://{bucket}/{prefix}/output\",\n",
    "    code_location=f\"s3://{bucket}/{prefix}/output\",\n",
    "    base_job_name=training_job_name,\n",
    "    tags=[{'Key': config.TAG_KEY, 'Value': config.SOLUTION_PREFIX}],\n",
    "    sagemaker_session=sess,\n",
    "    volume_size=30,\n",
    "    env={\n",
    "        'MMS_DEFAULT_RESPONSE_TIMEOUT': '500'\n",
    "    },\n",
    "    debugger_hook_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce0e1018-a7bc-4816-bf15-d86817e82b30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml.g4dn.2xlarge\n"
     ]
    }
   ],
   "source": [
    "print(train_instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d9eae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "re_estimator.fit({\n",
    "    \"train\": f\"s3://{bucket}/{prefix}/train/\",\n",
    "    \"validation\": f\"s3://{bucket}/{prefix}/validation/\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a5a038-2cf8-4699-9767-73e99528b65d",
   "metadata": {},
   "source": [
    "## 3.3. Deploy & run Inference on the fine-tuned model\n",
    "\n",
    "A trained model does nothing on its own. We now want to use the model to perform inference. For this example, it means predicting the semantic relation label of two text string within an input text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee40ac57",
   "metadata": {},
   "source": [
    "We'll use the unique solution prefix to name the model and endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c3afe72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_instance_type = config.HOSTING_INSTANCE_TYPE\n",
    "\n",
    "endpoint_name_finetune = f\"{config.SOLUTION_PREFIX}-re-finetune-endpoint-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b724191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "finetuned_predictor = re_estimator.deploy(\n",
    "    endpoint_name=endpoint_name_finetune,\n",
    "    instance_type=inference_instance_type,\n",
    "    initial_instance_count=1,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a44448",
   "metadata": {},
   "source": [
    "When calling our new endpoint from the notebook, we use a Amazon\n",
    "SageMaker SDK\n",
    "[`Predictor`](https://sagemaker.readthedocs.io/en/stable/predictors.html).\n",
    "A `Predictor` is used to send data to an endpoint (as part of a request),\n",
    "and interpret the response. Our `estimator.deploy` command returned a\n",
    "`Predictor` but, by default, it will send and receive numpy arrays. Our\n",
    "endpoint expects to receive (and also sends) JSON formatted objects, so\n",
    "we modify the `Predictor` to use JSON instead of the PyTorch endpoint\n",
    "default of numpy arrays. JSON is used here because it is a standard\n",
    "endpoint format and the endpoint response can contain nested data\n",
    "structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44818f5a",
   "metadata": {},
   "source": [
    "With our model successfully deployed and our predictor configured, we can\n",
    "try out the relationship extraction model out on example inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67ec2ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Label_id': 14, 'Label': 'Other'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_predictor.predict(\n",
    "    data={\n",
    "        'sequence': 'Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly.',\n",
    "        'entity_one_start': 0,\n",
    "        'entity_one_end': 6,\n",
    "        'entity_two_start': 7,\n",
    "        'entity_two_end': 16\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871318a2-f7f3-4a2e-9e8c-339e4e327681",
   "metadata": {},
   "source": [
    "Next, let's query the deployed endpoint to get for the prediction for each test example located in `../data/semeval2010t8/test/test.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40443558-6b60-476f-ad42-c52c6a715d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils_relation_extraction import parse_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2647df9b-61fa-45c9-aaaf-8b3bb20b87cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples, ground_truth = parse_file(\"../data/semeval2010t8/test/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8e54765-f035-4431-b6b5-b38c96107b79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_labels = []\n",
    "for each_example in examples:\n",
    "    prediction_labels.append(\n",
    "        finetuned_predictor.predict(each_example)[\"Label\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d6991f2-640f-4b29-aa10-a91ace12b6af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(prediction_labels, ground_truth)\n",
    "f1_macro = f1_score(prediction_labels, ground_truth, average='macro')\n",
    "f1_micro = f1_score(prediction_labels, ground_truth, average='micro')\n",
    "\n",
    "result = {\"Accuracy\": [accuracy], \"F1 Macro\": [f1_macro], \"F1 Micro\": [f1_micro]}\n",
    "\n",
    "result = pd.DataFrame.from_dict(result, orient='index', columns=[\"No HPO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a18516c-d6b6-4e44-aac7-225fcb7187b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No HPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.167096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Macro</th>\n",
       "      <td>0.015071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Micro</th>\n",
       "      <td>0.167096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            No HPO\n",
       "Accuracy  0.167096\n",
       "F1 Macro  0.015071\n",
       "F1 Micro  0.167096"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef29cb-da92-4908-9075-b142bcac2d73",
   "metadata": {},
   "source": [
    "Since the task is essentially multiclass classification task, we use accuracy, f1 macro, and f1 micro as the evaluation scores. For each of them, higher value indicates better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faf5549-e982-4e16-a721-505ee642205c",
   "metadata": {},
   "source": [
    "## 3. Finetune the pre-trained model on a custom dataset with automatic model tuning (AMT)\n",
    "\n",
    "Amazon SageMaker automatic model tuning, also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose. We will use a [HyperparameterTuner](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html) object to interact with Amazon SageMaker hyperparameter tuning APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "23efc592-b486-427c-8e65-82c6811d4715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter, IntegerParameter, CategoricalParameter, HyperparameterTuner\n",
    "\n",
    "\n",
    "# Define objective metric per framework, based on which the best model will be selected.\n",
    "metric_definitions = {\n",
    "    \"metrics\": [{\"Name\": \"validation_accuracy\", \"Regex\": \"valid_accuracy=([0-9\\\\.]+)\"}],\n",
    "    \"type\": \"Maximize\",\n",
    "}\n",
    "\n",
    "# You can select from the hyperparameters supported by the model, and configure ranges of values to be searched for training the optimal model.(https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html)\n",
    "hyperparameter_ranges = {\n",
    "    \"learning-rate\": ContinuousParameter(0.0001, 0.001, scaling_type=\"Logarithmic\"),\n",
    "    #\"max-epoch\": IntegerParameter(3, 8),\n",
    "}\n",
    "\n",
    "# Increase the total number of training jobs run by AMT, for increased accuracy (and training time).\n",
    "max_jobs = 2\n",
    "# Change parallel training jobs run by AMT to reduce total training time, constrained by your account limits.\n",
    "# if max_jobs=max_parallel_jobs then Bayesian search turns to Random.\n",
    "max_parallel_jobs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82492e83-8463-4e21-838c-ca8dccf6a81a",
   "metadata": {},
   "source": [
    "### 3.1. Fine-tuning with hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac385782-a696-4139-a05c-584f62df86b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuning_job_name = f\"{config.SOLUTION_PREFIX}-re-hpo\"\n",
    "\n",
    "hyperparameters = {\n",
    "    \"max-epoch\": 2,\n",
    "    \"weight-decay\": 0,\n",
    "    \"batch-size\": 8,\n",
    "    \"accumulate-grad-batches\": 1,\n",
    "    \"gradient-clip-val\": 1.0\n",
    "}\n",
    "\n",
    "\n",
    "estimator = PyTorch(\n",
    "    framework_version='1.10.0',\n",
    "    py_version='py38',\n",
    "    entry_point='entry_point.py',\n",
    "    source_dir='../containers/relationship_extraction',\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=aws_role,\n",
    "    instance_count=1,\n",
    "    instance_type=train_instance_type,\n",
    "    output_path=f\"s3://{bucket}/{prefix}/output\",\n",
    "    code_location=f\"s3://{bucket}/{prefix}/output\",\n",
    "    base_job_name=tuning_job_name,\n",
    "    tags=[{'Key': config.TAG_KEY, 'Value': config.SOLUTION_PREFIX}],\n",
    "    sagemaker_session=sess,\n",
    "    volume_size=30,\n",
    "    env={\n",
    "        'MMS_DEFAULT_RESPONSE_TIMEOUT': '500'\n",
    "    },\n",
    "    debugger_hook_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f220852-fd63-4124-a22e-96c358ef90cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: sagemaker-soln-docum-230628-0859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "re_tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    metric_definitions[\"metrics\"][0][\"Name\"],\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions[\"metrics\"],\n",
    "    max_jobs=max_jobs,\n",
    "    max_parallel_jobs=max_parallel_jobs,\n",
    "    objective_type=metric_definitions[\"type\"],\n",
    "    base_tuning_job_name=tuning_job_name,\n",
    ")\n",
    "\n",
    "re_tuner.fit({\n",
    "    \"train\": f\"s3://{bucket}/{prefix}/train/\",\n",
    "    \"validation\": f\"s3://{bucket}/{prefix}/validation/\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ee58c-8b3c-4432-a020-e7bdd0ddbbfe",
   "metadata": {},
   "source": [
    "### 3.2. Deploy & run Inference on the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd63e7fb-9838-4d01-9d8d-93a2dce655fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "endpoint_name_hpo = f\"{config.SOLUTION_PREFIX}-re-hpo-endpoint\"\n",
    "\n",
    "finetuned_predictor_hpo = re_tuner.deploy(\n",
    "    endpoint_name=endpoint_name_hpo,\n",
    "    instance_type=inference_instance_type,\n",
    "    initial_instance_count=1,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73748c15-8969-47e8-a494-6892e67aa21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_labels_hpo = []\n",
    "for each_example in examples:\n",
    "    prediction_labels_hpo.append(\n",
    "        finetuned_predictor_hpo.predict(each_example)[\"Label\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1f9b39ab-eb33-42e4-b32e-4491dc39bbbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "accuracy_hpo = accuracy_score(prediction_labels_hpo, ground_truth)\n",
    "f1_macro_hpo = f1_score(prediction_labels_hpo, ground_truth, average='macro')\n",
    "f1_micro_hpo = f1_score(prediction_labels_hpo, ground_truth, average='micro')\n",
    "\n",
    "\n",
    "result_hpo = {\"Accuracy\": [accuracy_hpo], \"F1 Macro\": [f1_macro_hpo], \"F1 Micro\": [f1_micro_hpo]}\n",
    "\n",
    "result_hpo = pd.DataFrame.from_dict(result_hpo, orient='index', columns=[\"With HPO\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "42a9fd14-4698-48e8-9968-578b93285cd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No HPO</th>\n",
       "      <th>With HPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.167096</td>\n",
       "      <td>0.167096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Macro</th>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.015071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Micro</th>\n",
       "      <td>0.167096</td>\n",
       "      <td>0.167096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            No HPO  With HPO\n",
       "Accuracy  0.167096  0.167096\n",
       "F1 Macro  0.015071  0.015071\n",
       "F1 Micro  0.167096  0.167096"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([result, result_hpo], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee2943-83a3-4e9d-b33b-8503b7a0cb1e",
   "metadata": {},
   "source": [
    "We can see results with hyperparameter optimization shows better performance on the hold-out test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9919fae",
   "metadata": {},
   "source": [
    "## 3.3. Clean Up the endpoint\n",
    "\n",
    "When you've finished with the summarization endpoint (and associated\n",
    "endpoint-config), make sure that you delete it to avoid accidental\n",
    "charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "13b66389-ae45-446c-93ea-6db4d93fcbae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: sagemaker-soln-documents-js-ewrtgp-re-f-2023-06-28-08-30-00-319\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: sagemaker-soln-documents-js-ewrtgp-re-finetune-endpoint-1\n",
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-soln-documents-js-ewrtgp-re-finetune-endpoint-1\n",
      "INFO:sagemaker:Deleting model with name: sagemaker-soln-docum-2023-06-28-09-34-44-865\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: sagemaker-soln-documents-js-ewrtgp-re-hpo-endpoint\n",
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-soln-documents-js-ewrtgp-re-hpo-endpoint\n"
     ]
    }
   ],
   "source": [
    "#### # Delete the SageMaker endpoint and the attached resources\n",
    "finetuned_predictor.delete_model()\n",
    "finetuned_predictor.delete_endpoint()\n",
    "\n",
    "finetuned_predictor_hpo.delete_model()\n",
    "finetuned_predictor_hpo.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
