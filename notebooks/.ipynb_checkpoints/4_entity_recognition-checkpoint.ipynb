{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e36183",
   "metadata": {},
   "source": [
    "# Document Understanding Solution - Name Entity Recognition\n",
    "\n",
    "Named entity recognition (NER) seeks to locate and classify named entities in text into pre-defined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc. In this notebook, we demonstrate three use cases of Name Entity Recognition:\n",
    "\n",
    "1. How to directly deploy a pretrained Transformer-based name entity recognition model to perform inference.\n",
    "2. How to fine-tune a pre-trained Transformer model on a custom dataset, and then run inference on the fine-tuned model.\n",
    "3. How to run [SageMaker Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html) (a hyperparameter optimization procedure) to find the best model compared with the model fine-tuned in point 2. The performance of the optimal model and model fine-tuned in point 2 is evaluated on a hold-out test data. \n",
    "\n",
    "**Note**: When running this notebook on SageMaker Studio, you should make\n",
    "sure the `PyTorch 1.10 Python 3.8 CPU Optimized` image/kernel is used. When\n",
    "running this notebook on SageMaker Notebook Instance, you should make\n",
    "sure the 'sagemaker-soln' kernel is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0097f0b5",
   "metadata": {},
   "source": [
    "This solution relies on a config file to run the provisioned AWS resources. Run the cell below to generate that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ec3ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import json\n",
    "\n",
    "client = boto3.client('servicecatalog')\n",
    "cwd = os.getcwd().split('/')\n",
    "i= cwd.index('S3Downloads')\n",
    "pp_name = cwd[i + 1]\n",
    "pp = client.describe_provisioned_product(Name=pp_name)\n",
    "record_id = pp['ProvisionedProductDetail']['LastSuccessfulProvisioningRecordId']\n",
    "record = client.describe_record(Id=record_id)\n",
    "\n",
    "keys = [ x['OutputKey'] for x in record['RecordOutputs'] if 'OutputKey' in x and 'OutputValue' in x]\n",
    "values = [ x['OutputValue'] for x in record['RecordOutputs'] if 'OutputKey' in x and 'OutputValue' in x]\n",
    "stack_output = dict(zip(keys, values))\n",
    "\n",
    "with open(f'/root/S3Downloads/{pp_name}/stack_outputs.json', 'w') as f:\n",
    "    json.dump(stack_output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d3edc7-2b6d-429a-a57b-568afbe0d7d6",
   "metadata": {},
   "source": [
    "## 1. Set Up\n",
    "\n",
    "Before executing the notebook, there are some initial steps required for setup. This notebook requires latest version of sagemaker and ipywidgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd68ceeb-ab12-40c7-b972-1c35eb96b36b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///root/S3Downloads/jumpstart-prod-doc_ewrtgp/notebooks/../wheelhouse\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.8/site-packages (2.168.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.0.6)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.8/site-packages (2.13.1)\n",
      "Processing /root/S3Downloads/jumpstart-prod-doc_ewrtgp/wheelhouse/seqeval-1.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.22.2)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.11.2)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.4.1)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.8/site-packages (from sagemaker) (2.5.1)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.17.3)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (3.19.4)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: PyYAML==6.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.26.162)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.5.6)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (8.0.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.15.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (2022.2.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.8/site-packages (from seqeval) (1.0.2)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.1)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.162 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.29.162)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.7.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (60.9.3)\n",
      "Requirement already satisfied: black in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (22.1.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (3.0.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (2.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (0.19.3)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (5.12.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (1.3.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2021.3)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.8/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (0.9.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (8.0.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (0.4.3)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (4.9.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (19.0.0)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker ipywidgets datasets seqeval --find-links file://$PWD/../wheelhouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a305c1f3",
   "metadata": {},
   "source": [
    "We start by importing a variety of packages that will be used throughout\n",
    "the notebook. One of the most important packages is the Amazon SageMaker\n",
    "Python SDK (i.e. `import sagemaker`). We also import modules from our own\n",
    "custom (and editable) package that can be found at `../package`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85548d93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "import sys\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "sys.path.insert(0, '../package')\n",
    "from package import config, utils\n",
    "\n",
    "aws_role = config.IAM_ROLE\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d574bbe",
   "metadata": {},
   "source": [
    "Up next, we define the current folder and create a SageMaker client (from\n",
    "`boto3`). We can use the SageMaker client to call SageMaker APIs\n",
    "directly, as an alternative to using the Amazon SageMaker SDK. We'll use\n",
    "it at the end of the notebook to delete certain resources that are\n",
    "created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df87c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_folder = utils.get_current_folder(globals())\n",
    "sagemaker_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926eac3b-0c40-4f87-8dfe-4090526063f0",
   "metadata": {},
   "source": [
    "## 2. Run inference on the pre-trained name entity recognition model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9774fe",
   "metadata": {},
   "source": [
    "We'll use the unique solution prefix to name the model and endpoint. Up next, we need to define the Amazon SageMaker Model which references\n",
    "the source code and the specifies which container to use. \n",
    "\n",
    "This is a Named Entity Generation model [En_core_web_md](https://spacy.io/models/en#en_core_web_md) from the [spaCy](spacy.io) library. It takes a text string as input and predicts named entities in the input text. \n",
    "\n",
    "The pre-trained model from the spaCy library doesn't rely on a specific deep learning framework. Just for consistency with the other notebooks we'll continue to use the PyTorchModel from the Amazon SageMaker Python SDK. Using PyTorchModel and setting the framework_version argument, means that our deployed model will run inside a container that has PyTorch pre-installed. Other requirements can be installed by defining a `requirements.txt` file at the specified source_dir location. We use the `entry_point` argument to reference the code (within `source_dir`) that should be run for model inference: functions called `model_fn`, `input_fn`, `predict_fn` and `output_fn` are expected to be defined. And lastly, you can pass `model_data` from a training job, but we are going to load the pre-trained model in the source code running on the endpoint. We still need to provide `model_data`, so we pass an empty archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72e8d25-7de0-4268-a835-8ead6a744733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = f\"{config.SOLUTION_PREFIX}-entity-recognition-endpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d721f3e4-6c7d-4a76-b757-409b7bd2d4d5",
   "metadata": {},
   "source": [
    "### 2.1. Deploy an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd9fab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PyTorchModel(\n",
    "    model_data=f\"{config.SOURCE_S3_PATH}/artifacts/models/empty.tar.gz\",\n",
    "    entry_point=\"entry_point.py\",\n",
    "    source_dir=\"../containers/entity_recognition\",\n",
    "    role=config.IAM_ROLE,\n",
    "    framework_version=\"1.5.0\",\n",
    "    py_version=\"py3\",\n",
    "    code_location=\"s3://\" + config.S3_BUCKET + \"/code\",\n",
    "    env={\n",
    "        \"MMS_DEFAULT_RESPONSE_TIMEOUT\": \"3000\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf9b548",
   "metadata": {},
   "source": [
    "Using this Amazon SageMaker Model, we can deploy a HTTPS endpoint on a\n",
    "dedicated instance. We choose to deploy the endpoint on a single\n",
    "ml.p3.2xlarge instance (or ml.g4dn.2xlarge if unavailable in this\n",
    "region). You can expect this deployment step to take\n",
    "around 5 minutes. After approximately 15 dashes, you can expect to see an\n",
    "exclamation mark which indicates a successful deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e17b3015",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor = model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    instance_type=config.HOSTING_INSTANCE_TYPE,\n",
    "    initial_instance_count=1,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcc1ac5",
   "metadata": {},
   "source": [
    "When you're trying to update the model for development purposes, but\n",
    "experiencing issues because the model/endpoint-config/endpoint already\n",
    "exists, you can delete the existing model/endpoint-config/endpoint by\n",
    "uncommenting and running the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55126363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "# sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a55b5d5",
   "metadata": {},
   "source": [
    "When calling our new endpoint from the notebook, we use a Amazon\n",
    "SageMaker SDK\n",
    "[`Predictor`](https://sagemaker.readthedocs.io/en/stable/predictors.html).\n",
    "A `Predictor` is used to send data to an endpoint (as part of a request),\n",
    "and interpret the response. Our `model.deploy` command returned a\n",
    "`Predictor` but, by default, it will send and receive numpy arrays. Our\n",
    "endpoint expects to receive (and also sends) JSON formatted objects, so\n",
    "we modify the `Predictor` to use JSON instead of the PyTorch endpoint\n",
    "default of numpy arrays. JSON is used here because it is a standard\n",
    "endpoint format and the endpoint response can contain nested data\n",
    "structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93fda1d-59f0-4845-937d-efd966011673",
   "metadata": {},
   "source": [
    "### 2.2. Example input sentences for inference & Query endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaa0e3f",
   "metadata": {},
   "source": [
    "With our model successfully deployed and our predictor configured, we can\n",
    "try out the entity recognizer out on example inputs. All we need to do is\n",
    "construct a dictionary object with a single key called `text` and provide\n",
    "the the input string. We call `predict` on our predictor and we should\n",
    "get a response from the endpoint that contains our entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36b16f42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {'text': 'Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly.'}\n",
    "response = predictor.predict(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb93be99",
   "metadata": {},
   "source": [
    "We have the responce and we can print out the named entities and noun\n",
    "chunks that have been extracted from the text above. You will see the\n",
    "verbatim text of each alongside its location in the original text (given\n",
    "by start and end character indexes). Usually a document will contain many\n",
    "more noun chunks than named entities, but named entities have an\n",
    "additional field called `label` that indicates the class of the named\n",
    "entity. Since the spaCy model was trained on the OneNotes 5 corpus, it\n",
    "uses the following classes:\n",
    "\n",
    "| TYPE | DESCRIPTION |\n",
    "|---|---|\n",
    "| PERSON | People, including fictional. |\n",
    "| NORP | Nationalities or religious or political groups. |\n",
    "| FAC | Buildings, airports, highways, bridges, etc. |\n",
    "| ORG | Companies, agencies, institutions, etc. |\n",
    "| GPE | Countries, cities, states. |\n",
    "| LOC | Non-GPE locations, mountain ranges, bodies of water. |\n",
    "| PRODUCT | Objects, vehicles, foods, etc. (Not services.) |\n",
    "| EVENT | Named hurricanes, battles, wars, sports events, etc. |\n",
    "| WORK_OF_ART | Titles of books, songs, etc. |\n",
    "| LAW | Named documents made into laws. |\n",
    "| LANGUAGE | Any named language. |\n",
    "| DATE | Absolute or relative dates or periods. |\n",
    "| TIME | Times smaller than a day. |\n",
    "| PERCENT | Percentage, including ”%“. |\n",
    "| MONEY | Monetary values, including unit. |\n",
    "| QUANTITY | Measurements, as of weight or distance. |\n",
    "| ORDINAL | “first”, “second”, etc. |\n",
    "| CARDINAL | Numerals that do not fall under another type. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26db066f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Amazon SageMaker', 'start_char': 0, 'end_char': 16, 'label': 'ORG'}]\n",
      "[{'text': 'Amazon SageMaker', 'start_char': 0, 'end_char': 16}, {'text': 'a fully managed service', 'start_char': 20, 'end_char': 43}, {'text': 'that', 'start_char': 44, 'end_char': 48}, {'text': 'every developer and data scientist', 'start_char': 58, 'end_char': 92}, {'text': 'the ability', 'start_char': 98, 'end_char': 109}, {'text': 'ML', 'start_char': 156, 'end_char': 158}]\n"
     ]
    }
   ],
   "source": [
    "print(response['entities'])\n",
    "print(response['noun_chunks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72717a27",
   "metadata": {},
   "source": [
    "You can try more examples above, but note that this model has been\n",
    "pretrained on the OneNotes 5 dataset. You may need to fine-tune this\n",
    "model with your own question answering data to obtain better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47561bab",
   "metadata": {},
   "source": [
    "### 2.3. Clean up the endpoint\n",
    "\n",
    "When you've finished with the summarization endpoint (and associated\n",
    "endpoint-config), make sure that you delete it to avoid accidental\n",
    "charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98be75f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c096-a18f-4a24-b7cd-c803b2b027ac",
   "metadata": {},
   "source": [
    "## 3. Finetune the pre-trained model on a custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0144ea9f-cf4b-4a24-9a0c-1a625a527831",
   "metadata": {},
   "source": [
    "Previously, we saw how to run inference on a pre-trained name entity recognition model. Next, we discuss how a model can be finetuned to a custom dataset. \n",
    "\n",
    "The model for fine-tuning attaches an token classification layer on each token embeddings outputted by the Text Embedding model\n",
    "and initializes the layer parameters to random values. The fine-tuning step fine-tunes \n",
    "all the model parameters to minimize prediction error on the input data and returns the fine-tuned model. The Text Embedding model we use in this demonstartion is [Distilbert-base-uncased](https://huggingface.co/distilbert-base-uncased) from FuggingFace. The dataset we fine-tune the model is [WikiANN](https://github.com/afshinrahimi/mmner) (which is also known as PAN-X english dataset. The WikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles annotated with `LOC` (location), `PER` (person), and `ORG` (organisation) tags in the [IOB2 format](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)).\n",
    "\n",
    "\n",
    "The model returned by fine-tuning can be further deployed for inference. Below are the instructions \n",
    "for how the training data should be formatted for input to the model. \n",
    "\n",
    "- **Input:**  A directory containing a `txt` format file.\n",
    "    - The first column of the `txt` format file should have tokens parsed from sentence.\n",
    "    - The second column should have the corresponding name entity tag.\n",
    "- **Output:** A trained model that can be deployed for inference. \n",
    " \n",
    "Below is an example of `txt` format file showing values in its first four columns. Note that the file should not have any header. For the prefix of `B`, `I`, `O` of the tag, please check the [IOB2 format](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) for details. The data for training and validation will be downloaded into directory `../data/wikiann` in the following section.\n",
    "\n",
    "|   |  | \n",
    "|--- |---|\n",
    "| R.H.   | B-ORG  |\n",
    "|Saunders| I-ORG |\n",
    "|(| O |\n",
    "|St.| B-ORG |\n",
    "|Lawrence| I-ORG |\n",
    "|River| I-ORG |\n",
    "|)| O |\n",
    "|(| O |\n",
    "|...   | ... |\n",
    " \n",
    "\n",
    "The WikiANN dataset is downloaded from [Dataset Homepage](https://github.com/afshinrahimi/mmner). [Apache 2.0 License](https://creativecommons.org/licenses/by-sa/4.0/legalcode).\n",
    "\n",
    "Citation:\n",
    "@inproceedings{rahimi-etal-2019-massively,\n",
    "    title = \"Massively Multilingual Transfer for {NER}\",\n",
    "    author = \"Rahimi, Afshin  and\n",
    "      Li, Yuan  and\n",
    "      Cohn, Trevor\",\n",
    "    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n",
    "    month = jul,\n",
    "    year = \"2019\",\n",
    "    address = \"Florence, Italy\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://www.aclweb.org/anthology/P19-1015\",\n",
    "    pages = \"151--164\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a3d89a-71ff-4093-9b4a-0d4a8a5eab25",
   "metadata": {},
   "source": [
    "### 3.1. Download, preprocess, and upload the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "806efd6c-1332-4cd2-a0a8-63b6ad1cb49e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-solutions-prod-us-east-1/0.2.0/Document-understanding/3.0.3/artifacts/data/wikiann/validation/dev.txt to ../data/wikiann/validation/dev.txt\n",
      "download: s3://sagemaker-solutions-prod-us-east-1/0.2.0/Document-understanding/3.0.3/artifacts/data/wikiann/train/train.txt to ../data/wikiann/train/train.txt\n",
      "download: s3://sagemaker-solutions-prod-us-east-1/0.2.0/Document-understanding/3.0.3/artifacts/data/wikiann/test/test.txt to ../data/wikiann/test/test.txt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $config.SOURCE_S3_PATH/artifacts/data/wikiann/ ../data/wikiann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b8dcb6-fa13-46c4-bfb0-9a56a39f1486",
   "metadata": {},
   "source": [
    "The dataset has been partitioned into `train.txt`, `dev.txt`, and `test.txt` data. Thus we don't need split the train data as what we do in previous notebooks. The`train.txt` and `dev.txt` will be used as training and validation data. The `test.txt` will be used as hold-out test data to evaluate model performance with / without hyperparameter optimization. Next, we upload them into S3 path which will be used as input for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0daa387-19e2-4733-ac32-54f54513cf7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "bucket = config.S3_BUCKET\n",
    "prefix = \"NER\"\n",
    "\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"train/data.txt\")\n",
    ").upload_file(\"../data/wikiann/train/train.txt\")\n",
    "\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"validation/data.txt\")\n",
    ").upload_file(\"../data/wikiann/validation/dev.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5ec83c-c0e1-4316-82e0-eeb53377afba",
   "metadata": {},
   "source": [
    "### 3.2. Set Training parameters\n",
    "\n",
    "Now that we are done with all the setup that is needed, we are ready to fine-tune our name entity recognition model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19565e6d-3f5b-45bc-bc94-0946939af28f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"pretrained-model\": \"distilbert-base-uncased\",\n",
    "    \"learning-rate\": 2e-6,\n",
    "    \"num-train-epochs\": 2,\n",
    "    \"batch-size\": 16,\n",
    "    \"weight-decay\": 1e-5,\n",
    "    \"early-stopping-patience\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b0e8f-9162-4b20-8645-dffecdc5d565",
   "metadata": {},
   "source": [
    "### 3.3. Fine-tuning without hyperparameter optimization\n",
    "\n",
    "We use the HuggingFace from the Amazon SageMaker Python SDK. The entry script is located under `../containers/entity_recognition/finetuning/training.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cc8fff9-994e-433b-b0f2-6638e4bbac27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_job_name = training_job_name = f\"{config.SOLUTION_PREFIX}-ner-finetune\"\n",
    "\n",
    "training_instance_type = config.TRAINING_INSTANCE_TYPE\n",
    "\n",
    "ner_estimator = HuggingFace(\n",
    "    pytorch_version='1.10.2',\n",
    "    py_version='py38',\n",
    "    transformers_version=\"4.17.0\",\n",
    "    entry_point='training.py',\n",
    "    source_dir='../containers/entity_recognition/finetuning',\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=aws_role,\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    output_path=f\"s3://{bucket}/{prefix}/output\",\n",
    "    code_location=f\"s3://{bucket}/{prefix}/output\",\n",
    "    tags=[{'Key': config.TAG_KEY, 'Value': config.SOLUTION_PREFIX}],\n",
    "    sagemaker_session=sess,\n",
    "    volume_size=30,\n",
    "    env={\n",
    "        'MMS_DEFAULT_RESPONSE_TIMEOUT': '500'\n",
    "    },\n",
    "    base_job_name = training_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c4285-fc94-4790-babe-e489ac6d9d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ner_estimator.fit({\n",
    "    \"train\": f\"s3://{bucket}/{prefix}/train/\",\n",
    "    \"validation\": f\"s3://{bucket}/{prefix}/validation/\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc8ccd4-a889-45ef-aa98-57b84bcff9b9",
   "metadata": {},
   "source": [
    "## 3.4. Deploy & run Inference on the fine-tuned model\n",
    "\n",
    "A trained model does nothing on its own. We now want to use the model to perform inference. For this example, it means predicting the entity tag of an input text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "086184e1-33b8-4096-847b-b17c6267782c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_instance_type = config.HOSTING_INSTANCE_TYPE\n",
    "endpoint_name_finetune = f\"{config.SOLUTION_PREFIX}-ner-finetune-endpoint\"\n",
    "\n",
    "finetuned_predictor = HuggingFaceModel(\n",
    "    model_data=ner_estimator.model_data,\n",
    "    source_dir='../containers/entity_recognition/finetuning',\n",
    "    entry_point='inference.py',\n",
    "    role=aws_role,\n",
    "    py_version=\"py38\",\n",
    "    pytorch_version='1.10.2',\n",
    "    transformers_version=\"4.17.0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d60c51-a06c-4782-b4fe-6a2caf1f9151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetuned_predictor.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    endpoint_name=endpoint_name_finetune,\n",
    ")\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e5055f-101b-4754-b749-c974ef9327cb",
   "metadata": {},
   "source": [
    "Before using the test examples to query the deployed endpoint, we firstly prepare the `test.txt` into the right format. We will create a list of words and a list of these words entity labels for each sentence. We will store this in a `pandas.DataFrame` by reading the `test.txt` and reading each sentence as a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d28991f-79a0-4ab6-86db-1fbeb5bab491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_tokens_and_ner_tags(filename):\n",
    "    with open(filename, 'r', encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "        split_list = [list(y) for x, y in itertools.groupby(lines, lambda z: z == '\\n') if not x]\n",
    "        tokens = [[x.split('\\t')[0].split(\"en:\")[1] for x in y] for y in split_list]\n",
    "        entities = [[x.split('\\t')[1][:-1] for x in y] for y in split_list] \n",
    "    return pd.DataFrame({'tokens': tokens, 'ner_tags': entities})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed885877-57e0-4456-a14a-7969738029ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = get_tokens_and_ner_tags('../data/wikiann/test/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "223db160-7c34-48f9-b8e4-aeb8c0aaec32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Shortly, afterward, ,, an, encouraging, respo...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[:, Kanye, West, featuring, Jamie, Foxx, —, ``...</td>\n",
       "      <td>[O, B-PER, I-PER, O, B-PER, I-PER, O, O, B-ORG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Blacktown, railway, station]</td>\n",
       "      <td>[B-ORG, I-ORG, I-ORG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['', Mycalesis, perseus, lalassis, '', (, Hewi...</td>\n",
       "      <td>[O, B-LOC, I-LOC, I-LOC, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Jonny, Lee, Miller, -, Eli, Stone, '']</td>\n",
       "      <td>[B-PER, I-PER, I-PER, O, B-ORG, I-ORG, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>[Tony, Stewart, ', '', (, PC4, ), ', '']</td>\n",
       "      <td>[B-PER, I-PER, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>[Maryland, Route, 472]</td>\n",
       "      <td>[B-ORG, I-ORG, I-ORG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>[Renton, ,, Washington]</td>\n",
       "      <td>[B-LOC, I-LOC, I-LOC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>[He, served, as, a, member, of, the, South, Ea...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>[|, align=left|, Free, Australia, Party]</td>\n",
       "      <td>[O, O, B-ORG, I-ORG, I-ORG]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "0     [Shortly, afterward, ,, an, encouraging, respo...   \n",
       "1     [:, Kanye, West, featuring, Jamie, Foxx, —, ``...   \n",
       "2                         [Blacktown, railway, station]   \n",
       "3     ['', Mycalesis, perseus, lalassis, '', (, Hewi...   \n",
       "4               [Jonny, Lee, Miller, -, Eli, Stone, '']   \n",
       "...                                                 ...   \n",
       "9995           [Tony, Stewart, ', '', (, PC4, ), ', '']   \n",
       "9996                             [Maryland, Route, 472]   \n",
       "9997                            [Renton, ,, Washington]   \n",
       "9998  [He, served, as, a, member, of, the, South, Ea...   \n",
       "9999           [|, align=left|, Free, Australia, Party]   \n",
       "\n",
       "                                               ner_tags  \n",
       "0     [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O,...  \n",
       "1     [O, B-PER, I-PER, O, B-PER, I-PER, O, O, B-ORG...  \n",
       "2                                 [B-ORG, I-ORG, I-ORG]  \n",
       "3            [O, B-LOC, I-LOC, I-LOC, O, O, O, O, O, O]  \n",
       "4             [B-PER, I-PER, I-PER, O, B-ORG, I-ORG, O]  \n",
       "...                                                 ...  \n",
       "9995                [B-PER, I-PER, O, O, O, O, O, O, O]  \n",
       "9996                              [B-ORG, I-ORG, I-ORG]  \n",
       "9997                              [B-LOC, I-LOC, I-LOC]  \n",
       "9998      [O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, O]  \n",
       "9999                        [O, O, B-ORG, I-ORG, I-ORG]  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a45770a-7525-4b85-9efd-385993098870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_type = \"application/list-text\"\n",
    "\n",
    "def query_endpoint(payload, endpoint_name):\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=content_type,\n",
    "        Body=json.dumps(payload).encode(\"utf-8\"),\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read())\n",
    "    predicted_label = model_predictions[\"predict_label\"]\n",
    "    token = model_predictions[\"token\"]\n",
    "    word_id = model_predictions[\"word_id\"]\n",
    "    return predicted_label, token, word_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5977b3f-e3a0-4a65-b29c-6b64eb5d2302",
   "metadata": {},
   "source": [
    "Now we query the endpoint. Each text string (corresponding to each row in `test.txt`) will be tokenzied as one or multiple tokens that could be sent into Transformer. When one text string is tokenzied as multiple tokens (for an example, text string `R.H.` will be tokensized as `R`, `.`, `H`, `.`), each of the four tokens will get a predicted name entity tag. In this case, we need duplicated the ground truth name entity tag of the text string for all the four tokens. As a result, the number of predicted and ground truth name entity tags is the same, and thus a evalution score can be computed. The predicted result `word_id` is used to identify the tokens that belong to the same text string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eefacf21-8dca-48f4-a559-199fcc2b1dce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "batch_size = 10\n",
    "num_examples = test_data.shape[0]\n",
    "predicted_label, token, word_id = [], [], []\n",
    "\n",
    "for i in np.arange(0, num_examples, step=batch_size):\n",
    "    query_response_batch = query_endpoint(\n",
    "        test_data.iloc[i : (i + batch_size), :].tokens.values.tolist(),\n",
    "        endpoint_name_finetune,\n",
    "    )\n",
    "\n",
    "    predicted_label_batch, token_batch, word_id_batch = parse_response(query_response_batch)\n",
    "    predicted_label.extend(predicted_label_batch)\n",
    "    token.extend(token_batch)\n",
    "    word_id.extend(word_id_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccc8905-2f88-45a0-baf9-f234f31b7162",
   "metadata": {},
   "source": [
    "The returned predictions contain `predicted_label`, `token`, and `word_id`, each of which has the same number of rows (sentences) in `test_data`. For each element in the `predicted_label` (or `token` or `word_id`), it is another list, where each element corresponds to a text string in the corresponding sentence. Let's first do a sanity checking on the number of predictions being equal to the number of rows in `test_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9a424dd-c088-4931-97fe-9c02e8b24139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(predicted_label) == len(token) == len(word_id) == test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3920cdd2-3b07-47db-8a2a-b18fac390b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, word_ids_all):\n",
    "    label_all_tokens = True\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = word_ids_all[i]\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif label[word_idx] == '0':\n",
    "                label_ids.append(0)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54eeaf4-73ac-4372-b68b-da3ab29918bb",
   "metadata": {},
   "source": [
    "Next, because each text string can be tokenized into one or multiple tokens. We need duplicate the ground truth name entity tag of the text string to all the tokens that are associated to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25f21184-fd92-46a9-aeb8-5eb81b553bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_gt = tokenize_and_align_labels(test_data, word_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378e8850-f25d-4aaa-b495-68427c5cdfd3",
   "metadata": {},
   "source": [
    "Let's do another sanity checking that within each sentence, the number of tokens (word id) equals to the number of ground truth name entity tags we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f48fc17-8de2-454a-93ba-e07cf81d88ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, i in enumerate(predicted_label):\n",
    "    assert len(i) == len(token[idx]) == len(word_id[idx]) == len(predicted_label[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f36a4ed-ffac-4503-b484-f24c571d5d6d",
   "metadata": {},
   "source": [
    "Now we load evaluation metric to compute evaluation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "505d593d-6e19-4ad0-8a1f-9fe1b296d790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1449f75f-b707-4b96-8bed-08018771ba93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-e20ba34f8cc7>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0291593074798584,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading builder script",
       "rate": null,
       "total": 2472,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ebcf5cfff6a4492ad33f66a8a52e0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b5fb9d-972c-469b-9b81-8d8ffdc8497d",
   "metadata": {},
   "source": [
    "For details of evaluaton metrics, please check the [official documentation](https://huggingface.co/spaces/evaluate-metric/seqeval). For the overall precision, recall, F1, and accuracy, larger value indicates better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3958e06a-3963-4b2d-a611-41129fac9f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_all, predict_all, groundtruth_all = [], [], []\n",
    "\n",
    "for idx, i in enumerate(predicted_label):\n",
    "    tmp_token, tmp_predict, tmp_gt = [], [], []\n",
    "    for idx2, each_token in enumerate(token[idx]):\n",
    "        if each_token in ['[CLS]', '[SEP]']: # exclude the CLS and SEP tokens\n",
    "            continue\n",
    "        assert len(i) == len(labels_gt[idx]) == len(token[idx])\n",
    "        tmp_token.append(each_token)\n",
    "        tmp_predict.append(i[idx2])\n",
    "        tmp_gt.append(labels_gt[idx][idx2])\n",
    "    assert len(tmp_token) == len(tmp_predict) == len(tmp_gt)\n",
    "    token_all.append(tmp_token)\n",
    "    predict_all.append(tmp_predict)\n",
    "    groundtruth_all.append(tmp_gt)\n",
    "    \n",
    "assert [-100 not in x for x in groundtruth_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83a41255-92e9-4e52-81b8-a73e1f2df60b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = metric.compute(predictions=predict_all, references=groundtruth_all)\n",
    "result = {\"precision\": [metrics[\"overall_precision\"]], \"recall\": [metrics[\"overall_recall\"]], \"f1\": [metrics[\"overall_f1\"]], \"accuracy\": [metrics[\"overall_accuracy\"]]}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce00b05a-e786-4450-9d53-ce1da72e70d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame.from_dict(result, orient='index', columns=[\"No HPO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d048416-db8c-4b6b-93d3-a80661edd5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No HPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.621406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.647711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.634286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.857885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             No HPO\n",
       "precision  0.621406\n",
       "recall     0.647711\n",
       "f1         0.634286\n",
       "accuracy   0.857885"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653a2d4f-c306-4922-9754-f6af8f22ab23",
   "metadata": {},
   "source": [
    "## 4. Finetune the pre-trained model on a custom dataset with automatic model tuning (AMT)\n",
    "\n",
    "Amazon SageMaker automatic model tuning, also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose. We will use a [HyperparameterTuner](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html) object to interact with Amazon SageMaker hyperparameter tuning APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4fb13a3-3d97-4f1a-8f26-a60cd902fa8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter, IntegerParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameters_range = {\n",
    "    \"learning-rate\": ContinuousParameter(1e-5, 0.1, scaling_type=\"Logarithmic\"),\n",
    "    \"weight-decay\": ContinuousParameter(1e-6, 1e-2, scaling_type=\"Logarithmic\"),\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    \"pretrained-model\": \"distilbert-base-uncased\",\n",
    "    \"num-train-epochs\": 3,\n",
    "    \"batch-size\": 16,\n",
    "    \"token-column-name\": \"tokens\",\n",
    "    \"tag-column-name\": \"ner_tags\",\n",
    "    \"early-stopping-patience\": 3,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84cd14-af9b-4ede-a21a-98d8450c7d87",
   "metadata": {},
   "source": [
    "### 4.1. Fine-tuning with hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83167800-e586-4714-80c5-c23300563377",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: sagemaker-soln-docum-230628-0539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuning_job_name = f\"{config.SOLUTION_PREFIX}-ner-hpo\"\n",
    "\n",
    "\n",
    "estimator = HuggingFace(\n",
    "    pytorch_version='1.10.2',\n",
    "    py_version='py38',\n",
    "    transformers_version=\"4.17.0\",\n",
    "    entry_point='training.py',\n",
    "    source_dir='../containers/entity_recognition/finetuning',\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=aws_role,\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    output_path=f\"s3://{bucket}/{prefix}/output\",\n",
    "    code_location=f\"s3://{bucket}/{prefix}/output\",\n",
    "    tags=[{'Key': config.TAG_KEY, 'Value': config.SOLUTION_PREFIX}],\n",
    "    sagemaker_session=sess,\n",
    "    volume_size=30,\n",
    "    env={\n",
    "        'MMS_DEFAULT_RESPONSE_TIMEOUT': '500'\n",
    "    }\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    \"f1\",\n",
    "    hyperparameters_range,\n",
    "    [{\"Name\": \"f1\", \"Regex\": \"'eval_f1': ([0-9\\\\.]+)\"}],\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=\"Maximize\",\n",
    "    base_tuning_job_name=tuning_job_name,\n",
    ")\n",
    "\n",
    "tuner.fit({\n",
    "    \"train\": f\"s3://{bucket}/{prefix}/train/\",\n",
    "    \"validation\": f\"s3://{bucket}/{prefix}/validation/\",\n",
    "}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f591ef2a-e78d-4d4d-a656-c6d95873f56f",
   "metadata": {},
   "source": [
    "Fetch the exact tuning job name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47a2431a-5a18-44c6-835c-02a432596766",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-soln-docum-230628-0539'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client = boto3.Session().client(\"sagemaker\")\n",
    "\n",
    "tuning_job_name = tuner.latest_tuning_job.name\n",
    "tuning_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "306dce71-916d-4c46-9d4e-af279f327db1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 training jobs have completed\n"
     ]
    }
   ],
   "source": [
    "tuning_job_result = sm_client.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuning_job_name\n",
    ")\n",
    "\n",
    "status = tuning_job_result[\"HyperParameterTuningJobStatus\"]\n",
    "if status != \"Completed\":\n",
    "    print(\"Reminder: the tuning job has not been completed.\")\n",
    "\n",
    "job_count = tuning_job_result[\"TrainingJobStatusCounters\"][\"Completed\"]\n",
    "print(\"%d training jobs have completed\" % job_count)\n",
    "\n",
    "is_maximize = (\n",
    "    tuning_job_result[\"HyperParameterTuningJobConfig\"][\"HyperParameterTuningJobObjective\"][\"Type\"]\n",
    "    != \"Maximize\"\n",
    ")\n",
    "objective_name = tuning_job_result[\"HyperParameterTuningJobConfig\"][\n",
    "    \"HyperParameterTuningJobObjective\"\n",
    "][\"MetricName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71def7ad-cefb-4670-b537-6fd4e4245f44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training jobs with valid objective: 4\n",
      "{'lowest': 0.0, 'highest': 0.8288232088088989}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-ab5cc1a02454>:11: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option(\"display.max_colwidth\", -1)  # Don't truncate TrainingJobName\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>weight-decay</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>sagemaker-soln-docum-230628-0539-003-5d365d1d</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.828823</td>\n",
       "      <td>2023-06-28 05:51:51+00:00</td>\n",
       "      <td>2023-06-28 05:58:23+00:00</td>\n",
       "      <td>392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025527</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>sagemaker-soln-docum-230628-0539-004-efd261c2</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2023-06-28 05:51:52+00:00</td>\n",
       "      <td>2023-06-28 05:58:30+00:00</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>sagemaker-soln-docum-230628-0539-002-831c1a00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2023-06-28 05:41:07+00:00</td>\n",
       "      <td>2023-06-28 05:50:15+00:00</td>\n",
       "      <td>548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040223</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>sagemaker-soln-docum-230628-0539-001-a04b6186</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2023-06-28 05:40:53+00:00</td>\n",
       "      <td>2023-06-28 05:50:06+00:00</td>\n",
       "      <td>553.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning-rate  weight-decay                                TrainingJobName  \\\n",
       "1  0.000105       0.000201      sagemaker-soln-docum-230628-0539-003-5d365d1d   \n",
       "0  0.025527       0.000007      sagemaker-soln-docum-230628-0539-004-efd261c2   \n",
       "2  0.006734       0.004764      sagemaker-soln-docum-230628-0539-002-831c1a00   \n",
       "3  0.040223       0.000718      sagemaker-soln-docum-230628-0539-001-a04b6186   \n",
       "\n",
       "  TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "1  Completed         0.828823            2023-06-28 05:51:51+00:00   \n",
       "0  Completed         0.000000            2023-06-28 05:51:52+00:00   \n",
       "2  Completed         0.000000            2023-06-28 05:41:07+00:00   \n",
       "3  Completed         0.000000            2023-06-28 05:40:53+00:00   \n",
       "\n",
       "            TrainingEndTime  TrainingElapsedTimeSeconds  \n",
       "1 2023-06-28 05:58:23+00:00  392.0                       \n",
       "0 2023-06-28 05:58:30+00:00  398.0                       \n",
       "2 2023-06-28 05:50:15+00:00  548.0                       \n",
       "3 2023-06-28 05:50:06+00:00  553.0                       "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tuner_analytics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "\n",
    "full_df = tuner_analytics.dataframe()\n",
    "\n",
    "if len(full_df) > 0:\n",
    "    df = full_df[full_df[\"FinalObjectiveValue\"] > -float(\"inf\")]\n",
    "    if len(df) > 0:\n",
    "        df = df.sort_values(\"FinalObjectiveValue\", ascending=False)\n",
    "        print(\"Number of training jobs with valid objective: %d\" % len(df))\n",
    "        print({\"lowest\": min(df[\"FinalObjectiveValue\"]), \"highest\": max(df[\"FinalObjectiveValue\"])})\n",
    "        pd.set_option(\"display.max_colwidth\", -1)  # Don't truncate TrainingJobName\n",
    "    else:\n",
    "        print(\"No training jobs have reported valid results yet.\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11428db-40d4-4231-8fa4-68da1222c940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[df[\"TrainingJobStatus\"] == \"Completed\"] # filter out the failed jobs\n",
    "output_path_best_tuning_job = os.path.join(f\"s3://{bucket}/{prefix}/output\", df[\"TrainingJobName\"].iloc[0], \"output\")\n",
    "\n",
    "print(f\"The output path of the best model from the hpo tuning is: {output_path_best_tuning_job}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc09cda-614a-4a69-9a9a-3d38d5b56663",
   "metadata": {},
   "source": [
    "### 4.2. Deploy & run Inference on the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9850eb8-12df-465d-b844-53cf1b442eda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name_hpo = f\"{config.SOLUTION_PREFIX}-ner-hpo-endpoint\"\n",
    "\n",
    "tuning_best_model = HuggingFaceModel(\n",
    "    model_data=os.path.join(output_path_best_tuning_job, \"model.tar.gz\"),\n",
    "    source_dir=\"../containers/entity_recognition/finetuning\",\n",
    "    entry_point=\"inference.py\",\n",
    "    role=aws_role,\n",
    "    py_version=\"py38\",\n",
    "    pytorch_version='1.10.2',\n",
    "    transformers_version=\"4.17.0\",\n",
    ")\n",
    "\n",
    "finetuned_predictor_hpo = tuning_best_model.deploy(\n",
    "    instance_type=inference_instance_type,\n",
    "    endpoint_name=endpoint_name_hpo,\n",
    "    initial_instance_count=1,\n",
    ")\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfb5d94d-f39e-498c-a95a-7d525fda2a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_type = \"application/list-text\"\n",
    "\n",
    "batch_size = 10\n",
    "num_examples = test_data.shape[0]\n",
    "predicted_label_hpo, token_hpo, word_id_hpo = [], [], []\n",
    "for i in np.arange(0, num_examples, step=batch_size):\n",
    "    query_response_batch = query_endpoint(\n",
    "        test_data.iloc[i : (i + batch_size), :].tokens.values.tolist(),\n",
    "        endpoint_name_hpo,\n",
    "    )\n",
    "\n",
    "    predicted_label_batch, token_batch, word_id_batch = parse_response(query_response_batch)\n",
    "    predicted_label_hpo.extend(predicted_label_batch)\n",
    "    token_hpo.extend(token_batch)\n",
    "    word_id_hpo.extend(word_id_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72848bcc-c09f-4313-885b-be1d1c80ea9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_all_hpo, predict_all_hpo, groundtruth_all_hpo = [], [], []\n",
    "\n",
    "for idx, i in enumerate(predicted_label_hpo):\n",
    "    tmp_token, tmp_predict, tmp_gt = [], [], []\n",
    "    for idx2, each_token in enumerate(token_hpo[idx]):\n",
    "        if each_token in ['[CLS]', '[SEP]']:\n",
    "            continue\n",
    "        assert len(i) == len(labels_gt[idx]) == len(token_hpo[idx])\n",
    "        tmp_token.append(each_token)\n",
    "        tmp_predict.append(i[idx2])\n",
    "        tmp_gt.append(labels_gt[idx][idx2])\n",
    "    assert len(tmp_token) == len(tmp_predict) == len(tmp_gt)\n",
    "    token_all_hpo.append(tmp_token)\n",
    "    predict_all_hpo.append(tmp_predict)\n",
    "    groundtruth_all_hpo.append(tmp_gt)\n",
    "    \n",
    "assert [-100 not in x for x in groundtruth_all_hpo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77285b00-2619-44fa-878e-e420eb8ac636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_hpo = metric.compute(predictions=predict_all_hpo, references=groundtruth_all)\n",
    "result_hpo = {\"precision\": [metrics_hpo[\"overall_precision\"]], \"recall\": [metrics_hpo[\"overall_recall\"]], \"f1\": [metrics_hpo[\"overall_f1\"]], \"accuracy\": [metrics_hpo[\"overall_accuracy\"]]}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97b11cee-2be1-40fe-820d-135ca9fc8d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_hpo = pd.DataFrame.from_dict(result_hpo, orient='index', columns=[\"With HPO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96515dc6-5dbc-4108-b348-143a0f1eda9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No HPO</th>\n",
       "      <th>With HPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.621406</td>\n",
       "      <td>0.811914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.647711</td>\n",
       "      <td>0.839227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.634286</td>\n",
       "      <td>0.825345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.857885</td>\n",
       "      <td>0.922633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             No HPO  With HPO\n",
       "precision  0.621406  0.811914\n",
       "recall     0.647711  0.839227\n",
       "f1         0.634286  0.825345\n",
       "accuracy   0.857885  0.922633"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([result, result_hpo], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d539868-9491-4cee-88d5-6609a51b21eb",
   "metadata": {},
   "source": [
    "We can see results with hyperparameter optimization shows better performance on the hold-out test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4edea-b0f5-46da-bf34-3d0b6e3e84aa",
   "metadata": {},
   "source": [
    "## 4.3. Clean Up the endpoint\n",
    "\n",
    "When you've finished with the summarization endpoint (and associated\n",
    "endpoint-config), make sure that you delete it to avoid accidental\n",
    "charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ab87ab1-7c3a-4897-8482-2978b9d23058",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: huggingface-pytorch-inference-2023-06-28-05-33-36-747\n",
      "INFO:sagemaker:Deleting model with name: huggingface-pytorch-inference-2023-06-28-05-59-26-571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'd8da2308-8ac4-4aff-b4d0-1c380b618b79',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd8da2308-8ac4-4aff-b4d0-1c380b618b79',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Wed, 28 Jun 2023 06:05:12 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Delete the SageMaker endpoint and the attached resources\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "finetuned_predictor.delete_model()\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name_finetune) ## cannot call finetuned_predictor.delete_endpoint() because 'HuggingFaceModel' object has no attribute 'delete_endpoint'\n",
    "sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_name_finetune)\n",
    "\n",
    "finetuned_predictor_hpo.delete_model()\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name_hpo)\n",
    "sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_name_hpo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a697799",
   "metadata": {},
   "source": [
    "## Next Stage\n",
    "\n",
    "We've just looked at how you can extract named entities and noun chunks\n",
    "from a document. Up next we'll look at a technique that can be used to\n",
    "classify relationships between entities.\n",
    "\n",
    "[Click here to continue with Relation Extraction.](./5_relationship_extraction.ipynb)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
