{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ec4968",
   "metadata": {},
   "source": [
    "# Document Understanding Solution - Question Answering\n",
    "\n",
    "Question Answering is useful when you want to query a large amount of text for specific information. Maybe you're interested in extracting the\n",
    "date a certain event happened. You can construct a question (or query) in natural language to retrive this information: e.g. 'When did Company X release Product Y?\". Similar to extractive summarization we saw in the last notebook, Question Answering will return a verbatim slice of the\n",
    "text as the answer. It won't generate new words to answer the question. In this notebook, we demonstrate three use cases of Questions and Answering:\n",
    "\n",
    "1. How to directly deploy a pretrained Transformer-based extractive question answering model to perform inference.\n",
    "2. How to fine-tune a pre-trained Transformer model on a custom dataset, and then run inference on the fine-tuned model.\n",
    "3. How to run [SageMaker Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html) (a hyperparameter optimization procedure) to find the best model compared with the model fine-tuned in point 2. The performance of the optimal model and model fine-tuned in point 2 is evaluated on a hold-out test data. \n",
    "\n",
    "**Note**: When running this notebook on SageMaker Studio, you should make\n",
    "sure the `PyTorch 1.10 Python 3.8 CPU Optimized` image/kernel is used. When\n",
    "running this notebook on SageMaker Notebook Instance, you should make\n",
    "sure the 'sagemaker-soln' kernel is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0a9792",
   "metadata": {},
   "source": [
    "This solution relies on a config file to run the provisioned AWS resources. Run the cell below to generate that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30cd05e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import json\n",
    "\n",
    "client = boto3.client('servicecatalog')\n",
    "cwd = os.getcwd().split('/')\n",
    "i= cwd.index('S3Downloads')\n",
    "pp_name = cwd[i + 1]\n",
    "pp = client.describe_provisioned_product(Name=pp_name)\n",
    "record_id = pp['ProvisionedProductDetail']['LastSuccessfulProvisioningRecordId']\n",
    "record = client.describe_record(Id=record_id)\n",
    "\n",
    "keys = [ x['OutputKey'] for x in record['RecordOutputs'] if 'OutputKey' in x and 'OutputValue' in x]\n",
    "values = [ x['OutputValue'] for x in record['RecordOutputs'] if 'OutputKey' in x and 'OutputValue' in x]\n",
    "stack_output = dict(zip(keys, values))\n",
    "\n",
    "with open(f'/root/S3Downloads/{pp_name}/stack_outputs.json', 'w') as f:\n",
    "    json.dump(stack_output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8296e689-282b-45a5-8984-c20aa3bbd97f",
   "metadata": {},
   "source": [
    "## 1. Set Up\n",
    "\n",
    "Before executing the notebook, there are some initial steps required for setup. This notebook requires latest version of sagemaker and ipywidgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2823cad2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///root/S3Downloads/jumpstart-prod-doc_ewrtgp/notebooks/../wheelhouse\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.8/site-packages (2.168.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.0.6)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (3.19.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.4.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.22.2)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.11.2)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.17.3)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.8/site-packages (from sagemaker) (2.5.1)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.26.162)\n",
      "Requirement already satisfied: PyYAML==6.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (6.0)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.5.6)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (8.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.1)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.162 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.29.162)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.7.0)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.5)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: black in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (22.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (60.9.3)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (3.0.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (5.12.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (0.19.3)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (1.3.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2021.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.8/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.30.0,>=1.29.162->boto3<2.0,>=1.26.131->sagemaker) (1.26.8)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (4.1.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (8.0.4)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (0.9.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (4.9.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (19.0.0)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker ipywidgets --find-links file://$PWD/../wheelhouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7862bd04-0ff8-435f-a64b-23f23978411d",
   "metadata": {},
   "source": [
    "We start by importing a variety of packages that will be used throughout\n",
    "the notebook. One of the most important packages is the Amazon SageMaker\n",
    "Python SDK (i.e. `import sagemaker`). We also import modules from our own\n",
    "custom (and editable) package that can be found at `../package`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "477d2cbf-0e1f-416c-be19-334408f8c170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import boto3\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.local import LocalSession\n",
    "\n",
    "sys.path.insert(0, '../package')\n",
    "from package import config, utils\n",
    "\n",
    "aws_role = config.IAM_ROLE\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4608967a",
   "metadata": {},
   "source": [
    "Up next, we define the current folder and create a SageMaker client (from\n",
    "`boto3`). We can use the SageMaker client to call SageMaker APIs\n",
    "directly, as an alternative to using the Amazon SageMaker SDK. We'll use\n",
    "it at the end of the notebook to delete certain resources that are\n",
    "created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d3ec119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_folder = utils.get_current_folder(globals())\n",
    "sagemaker_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8211d34f-c387-47b8-861a-b8b2f8952eff",
   "metadata": {},
   "source": [
    "## 2. Run inference on the pre-trained extractive question answering model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98361880",
   "metadata": {},
   "source": [
    "Our question answering system needs a machine learning model. In this\n",
    "section, we'll deploy a model to an Amazon SageMaker Endpoint and then\n",
    "invoke the endpoint from the notebook. We'll use a pre-trained model from\n",
    "the [transformers](https://huggingface.co/transformers/) library instead\n",
    "of training a model from scratch, specifically the BERT Large model that\n",
    "has been pre-trained on the SQuAD dataset.\n",
    "\n",
    "We'll use the unique solution prefix to name the model and endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "052b9bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = f\"{config.SOLUTION_PREFIX}-question-answering-endpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13553988-d00a-480c-b3b3-6c1957b82b67",
   "metadata": {},
   "source": [
    "### 2.1. Deploy an endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a5b89f",
   "metadata": {},
   "source": [
    "Up next, we need to define the Amazon SageMaker Model which references\n",
    "the source code and the specifies which container to use. \n",
    "\n",
    "Our pre-trained model is Extractive Question Answering model [bert-large-uncased-whole-word-masking-finetuned-squad](https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad) built on a Transformer model from Hugging Face. It takes two strings as inputs: the first string is a question and the second string is the context or any text you want to use to find the answer of the question, and it returns a sub-string from the context as an answer to the question.\n",
    "\n",
    "We use the PyTorchModel from the Amazon SageMaker Python SDK. Using PyTorchModel and setting the `framework_version` argument, means that our deployed model will run inside a container that has PyTorch pre-installed (i.e., downloading the model on the fly). Other requirements can be installed by defining a `requirements.txt` file at the specified source_dir location. We use the `entry_point` argument to reference the code (within `source_dir`) that should be run for model inference: functions called `model_fn`, `input_fn`, `predict_fn` and `output_fn` are expected to be defined. And lastly, you can pass `model_data` from a training job, but we are going to load the pre-trained model in the source code running on the endpoint. We still\n",
    "need to provide `model_data`, so we pass an empty archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf42ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PyTorchModel(\n",
    "    model_data=f\"{config.SOURCE_S3_PATH}/artifacts/models/empty.tar.gz\",\n",
    "    entry_point=\"entry_point.py\",\n",
    "    source_dir=\"../containers/question_answering\",\n",
    "    role=config.IAM_ROLE,\n",
    "    framework_version=\"1.5.0\",\n",
    "    py_version=\"py3\",\n",
    "    code_location=\"s3://\" + config.S3_BUCKET + \"/code\",\n",
    "    env={\n",
    "        \"MODEL_ASSETS_S3_BUCKET\": config.SOURCE_S3_BUCKET,\n",
    "        \"MODEL_ASSETS_S3_PREFIX\": f\"{config.SOURCE_S3_PREFIX}/artifacts/models/question_answering/\",\n",
    "        \"MMS_DEFAULT_RESPONSE_TIMEOUT\": \"3000\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeae2d6",
   "metadata": {},
   "source": [
    "Using this Amazon SageMaker Model, we can deploy a HTTPS endpoint on a\n",
    "dedicated instance. We choose to deploy the endpoint on a single\n",
    "ml.p3.2xlarge instance (or ml.g4dn.2xlarge if unavailable in this\n",
    "region). Our question answering model is transfomer that\n",
    "benefits from GPU optimization, and a ml.p3.2xlarge has a high\n",
    "performance NVIDIA V100 GPU that can reduce inference latency on each\n",
    "request. You can expect this deployment step to take around 5 minutes.\n",
    "After approximately 15 dashes, you can expect to see an exclamation mark\n",
    "which indicates a successful deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44fa009c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor = model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    instance_type=config.HOSTING_INSTANCE_TYPE,\n",
    "    initial_instance_count=1,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b033551",
   "metadata": {},
   "source": [
    "When you're trying to update the model for development purposes, but\n",
    "experiencing issues because the model/endpoint-config/endpoint already\n",
    "exists, you can delete the existing model/endpoint-config/endpoint by\n",
    "uncommenting and running the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f729a0dc",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "# sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8628e4b5",
   "metadata": {},
   "source": [
    "When calling our new endpoint from the notebook, we use a Amazon\n",
    "SageMaker SDK\n",
    "[`Predictor`](https://sagemaker.readthedocs.io/en/stable/predictors.html).\n",
    "A `Predictor` is used to send data to an endpoint (as part of a request),\n",
    "and interpret the response. Our `model.deploy` command returned a\n",
    "`Predictor` but, by default, it will send and receive numpy arrays. Our\n",
    "endpoint expects to receive (and also sends) JSON formatted objects, so\n",
    "we modify the `Predictor` to use JSON instead of the PyTorch endpoint\n",
    "default of numpy arrays. JSON is used here because it is a standard\n",
    "endpoint format and the endpoint response can contain nested data\n",
    "structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d812ca-733a-4002-8ea1-30995532d724",
   "metadata": {},
   "source": [
    "### 2.2. Example input sentences for inference & Query endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466c059",
   "metadata": {},
   "source": [
    "With our model successfully deployed and our predictor configured, we can\n",
    "try out the question answering model out on example inputs. All we need\n",
    "to do is construct a dictionary object with two keys. `context` is the\n",
    "text that we wish to retrieve information from. `question` is the natural\n",
    "language query which specifices what information we're interested in\n",
    "extracting. We call `predict` on our predictor and we should get a\n",
    "response from the endpoint that contains the most likely answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b4d3fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {'question': 'what is my name?', 'context': \"my name is thom\"}\n",
    "response = predictor.predict(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc66ed",
   "metadata": {},
   "source": [
    "We have the responce and we can print out the most likely answers that\n",
    "has been extracted from the text above. You'll see each answer has a\n",
    "confidence score used for ranking (but this score shouldn't be\n",
    "interpreted as a true probability). In addition to the verbatim answer,\n",
    "you also get the start and end character indexes of the answer from the\n",
    "original context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fda45bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.9793591499328613, 'start': 11, 'end': 15, 'answer': 'thom'}, {'score': 0.02019440196454525, 'start': 0, 'end': 15, 'answer': 'my name is thom'}, {'score': 4.349117443780415e-05, 'start': 3, 'end': 15, 'answer': 'name is thom'}]\n"
     ]
    }
   ],
   "source": [
    "print(response['answers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d283cd",
   "metadata": {},
   "source": [
    "You can try more examples above, but note that this model has been\n",
    "pretrained on the SQuAD dataset. You may need to fine-tune this model\n",
    "with your own question answering data to obtain better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b45a1",
   "metadata": {},
   "source": [
    "### 2.3. Clean up the endpoint\n",
    "\n",
    "When you've finished with the summarization endpoint (and associated\n",
    "endpoint-config), make sure that you delete it to avoid accidental\n",
    "charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4c5ac53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bd125a-aac2-41dd-81a2-9f51975b435c",
   "metadata": {},
   "source": [
    "## 3. Finetune the pre-trained model on a custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dd5a17-fd17-4f28-9184-bf803b850563",
   "metadata": {},
   "source": [
    "Previously, we saw how to run inference on a pre-trained extractive qusetion answering model. Next, we discuss how a model can be finetuned to a custom dataset. \n",
    "\n",
    "The Text Embedding model can be fine-tuned on any extractive question \n",
    "answering dataset in the same way the model available for inference has been \n",
    "fine-tuned on the SQuAD2.0 dataset.\n",
    "The model available for fine-tuning attaches an answer extracting layer to the Text Embedding model\n",
    "and initializes the layer parameters to random values. The fine-tuning step fine-tunes \n",
    "all the model parameters to minimize prediction error on the input data and returns the fine-tuned model.\n",
    "The model returned by fine-tuning can be further deployed for inference. Below are the instructions \n",
    "for how the training data should be formatted for input to the model. \n",
    "\n",
    "- **Input:**  A directory containing a 'data.csv' file.\n",
    "    - The first column of the 'data.csv' should have a question.\n",
    "    - The second column should have the corresponding context.\n",
    "    - The third column should have the integer character starting position for the answer in the context.\n",
    "    - The fourth column should have the integer character ending position for the answer in the context.\n",
    "- **Output:** A trained model that can be deployed for inference. \n",
    " \n",
    "Below is an example of 'data.csv' file showing values in its first four columns. Note that the file should not have any header.\n",
    "\n",
    "|   |  |  |   |\n",
    "|---|---|---|---|\n",
    "|In what country is Normandy located?|\tThe Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.|\t159|\t165\n",
    "|...   | ... |...  | ... |\n",
    " \n",
    "\n",
    "SQuAD2.0 dataset is downloaded from \n",
    "[Dataset Homepage](https://rajpurkar.github.io/SQuAD-explorer/). \n",
    "[CC BY-SA 4.0 License](https://creativecommons.org/licenses/by-sa/4.0/legalcode)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15883347-9cc7-45e9-b437-af90071e2261",
   "metadata": {},
   "source": [
    "### 3.1. Retrieve JumpStart Training artifacts\n",
    "Here, for the selected model, we retrieve the training docker container, the training algorithm source, the pre-trained model, and a python dictionary of the training hyper-parameters that the algorithm accepts with their default values. Note that the `model_version`=\"*\" fetches the latest model. Also, we do need to specify the `training_instance_type` to fetch `train_image_uri`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0202395-4568-40b1-bad0-d7b3905652c9",
   "metadata": {},
   "source": [
    "You can continue with the default model id, or can choose a different model from the dropdown generated upon running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1883bd2d-2548-4275-89ae-1e71985cbcab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = 'pytorch-eqa-bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f003483e-d87a-46e2-a8a6-b499666420d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the other available extractive question answering models are as below.\n",
      "\n",
      "huggingface-eqa-bert-base-cased\n",
      "huggingface-eqa-bert-base-multilingual-cased\n",
      "huggingface-eqa-bert-base-multilingual-uncased\n",
      "huggingface-eqa-bert-base-uncased\n",
      "huggingface-eqa-bert-large-cased\n",
      "huggingface-eqa-bert-large-cased-whole-word-masking\n",
      "huggingface-eqa-bert-large-uncased\n",
      "huggingface-eqa-bert-large-uncased-whole-word-masking\n",
      "huggingface-eqa-distilbert-base-cased\n",
      "huggingface-eqa-distilbert-base-multilingual-cased\n",
      "huggingface-eqa-distilbert-base-uncased\n",
      "huggingface-eqa-distilroberta-base\n",
      "huggingface-eqa-roberta-base\n",
      "huggingface-eqa-roberta-base-openai-detector\n",
      "huggingface-eqa-roberta-large\n",
      "pytorch-eqa-bert-base-cased\n",
      "pytorch-eqa-bert-base-multilingual-cased\n",
      "pytorch-eqa-bert-base-multilingual-uncased\n",
      "pytorch-eqa-bert-base-uncased\n",
      "pytorch-eqa-bert-large-cased\n",
      "pytorch-eqa-bert-large-cased-whole-word-masking\n",
      "pytorch-eqa-bert-large-cased-whole-word-masking-finetuned-squad\n",
      "pytorch-eqa-bert-large-uncased\n",
      "pytorch-eqa-bert-large-uncased-whole-word-masking\n",
      "pytorch-eqa-bert-large-uncased-whole-word-masking-finetuned-squad\n",
      "pytorch-eqa-distilbert-base-cased\n",
      "pytorch-eqa-distilbert-base-multilingual-cased\n",
      "pytorch-eqa-distilbert-base-uncased\n",
      "pytorch-eqa-distilroberta-base\n",
      "pytorch-eqa-roberta-base\n",
      "pytorch-eqa-roberta-base-openai-detector\n",
      "pytorch-eqa-roberta-large\n",
      "pytorch-eqa-roberta-large-openai-detector\n"
     ]
    }
   ],
   "source": [
    "# download JumpStart model_manifest file.\n",
    "boto3.client(\"s3\").download_file(\n",
    "    f\"jumpstart-cache-prod-{aws_region}\", \"models_manifest.json\", \"models_manifest.json\"\n",
    ")\n",
    "with open(\"models_manifest.json\", \"rb\") as json_file:\n",
    "    model_list = json.load(json_file)\n",
    "\n",
    "# filter-out all the Text Classification models from the manifest list.\n",
    "eqa_models_all_versions, eqa_models = [\n",
    "    model[\"model_id\"] for model in model_list if \"-eqa-\" in model[\"model_id\"]\n",
    "], []\n",
    "[eqa_models.append(model) for model in eqa_models_all_versions if model not in eqa_models]\n",
    "\n",
    "print(f\"All the other available extractive question answering models are as below.\\n\")\n",
    "for each in eqa_models:\n",
    "    print(f\"{each}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "89c4a5c1-44bb-4e6d-9fdc-5b83b14d23ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"huggingface-eqa-bert-base-uncased\" \n",
    "# model_id = \"pytorch-eqa-bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4afa8d7d-a11b-4d40-a07e-7eb290599a02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "\n",
    "model_version = \"*\"\n",
    "training_instance_type = config.TRAINING_INSTANCE_TYPE\n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    image_scope=\"training\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "# Retrieve the training script\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"training\"\n",
    ")\n",
    "# Retrieve the pre-trained model tarball to further fine-tune\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe09e1b6-df52-42dc-9fd9-bd1c7ed8a0eb",
   "metadata": {},
   "source": [
    "### 3.2. Set Training parameters\n",
    "\n",
    "Now that we are done with all the setup that is needed, we are ready to fine-tune our extractive question answering model. To begin, let us create a [``sageMaker.estimator.Estimator``](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) object. This estimator will launch the training job. \n",
    "\n",
    "There are two kinds of parameters that need to be set for training. \n",
    "\n",
    "The first one are the parameters for the training job. These include: (i) Training data path. This is S3 folder in which the input data is stored, (ii) Output path: This the s3 folder in which the training output is stored. (iii) Training instance type: This indicates the type of machine on which to run the training. Typically, we use GPU instances for these training. We defined the training instance type above to fetch the correct train_image_uri. \n",
    "\n",
    "The second set of parameters are algorithm specific training hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa0140f0-8b4a-4c3d-a5dc-db8bf4a37e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample training data is available in this bucket\n",
    "training_data_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
    "# For a quick demonstration of training we have created a random subset of SQuAD-v2 dataset.\n",
    "# For complete QNLI dataset replace \"SQuAD-v2-tiny\" with \"SQuAD-v2\" in the line below.\n",
    "training_data_prefix = \"training-datasets/SQuAD-v2-tiny/\"\n",
    "\n",
    "training_dataset_s3_path = f\"s3://{training_data_bucket}/{training_data_prefix}\"\n",
    "\n",
    "output_bucket = config.S3_BUCKET\n",
    "output_prefix = \"EQA\"\n",
    "\n",
    "s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb733bc6-1cc2-4d3b-a2c6-14662a29803f",
   "metadata": {},
   "source": [
    "For algorithm specific hyper-parameters, we start by fetching python dictionary of the training hyper-parameters that the algorithm accepts with their default values. This can then be overridden to custom values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bc4bd14-0f62-4935-996e-a8bfbc507241",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': '3', 'adam-learning-rate': '2e-05', 'batch-size': '16', 'reinitialize-top-layer': 'Auto', 'train-only-top-layer': 'False'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(model_id=model_id, model_version=model_version)\n",
    "\n",
    "# [Optional] Override default hyperparameters with custom values\n",
    "hyperparameters[\"batch-size\"] = \"16\"\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a1fe54-994c-48e2-9ff9-5a1423bc6393",
   "metadata": {},
   "source": [
    "### 3.3. Download, preprocess, and upload the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cec16438-fc18-4acd-a9f1-a644fc8bddcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://jumpstart-cache-prod-us-east-1/training-datasets/SQuAD-v2-tiny/data.csv to ../data/squad2/data.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $training_dataset_s3_path ../data/squad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a27b816-cc25-4b46-8a0e-da6ea7586ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../data/squad2/data.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be76ce3-f89e-4f72-876e-e7a69bc9d302",
   "metadata": {},
   "source": [
    "View the first five observations of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6da7c146-80ac-4e21-bf93-5e2f2de22957",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>159</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>159</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>159</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>159</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>94</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0  \\\n",
       "0  In what country is Normandy located?   \n",
       "1  In what country is Normandy located?   \n",
       "2  In what country is Normandy located?   \n",
       "3  In what country is Normandy located?   \n",
       "4    When were the Normans in Normandy?   \n",
       "\n",
       "                                                   1    2    3  \n",
       "0  The Normans (Norman: Nourmands; French: Norman...  159  165  \n",
       "1  The Normans (Norman: Nourmands; French: Norman...  159  165  \n",
       "2  The Normans (Norman: Nourmands; French: Norman...  159  165  \n",
       "3  The Normans (Norman: Nourmands; French: Norman...  159  165  \n",
       "4  The Normans (Norman: Nourmands; French: Norman...   94  117  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d166a2b-3e43-40b2-b3c1-735134644142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3d9ea2e-2186-4f09-9bf2-be7fe18dadcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d87190d-23cc-406e-ab7a-2a60967ae587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.to_csv(\"../data/squad2/split_train.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd81c4fd-f1e5-4269-850e-5cb9b29116b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "prefix = \"EQA\"\n",
    "boto3.Session().resource(\"s3\").Bucket(config.S3_BUCKET).Object(\n",
    "    os.path.join(prefix, \"train/data.csv\")\n",
    ").upload_file(\"../data/squad2/split_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a61738-971e-4e08-93c9-689edb450e8c",
   "metadata": {},
   "source": [
    "Process the text data to make them ready for inference. In particular, the question with multiple answers are formulated as multiple rows in above `data`. For an example, one question with three answers will yield three rows in the `data`. Each row corresponds to one answer and has the same question content. In evalution, we combine those rows that correspond to the same question. As a result, each input in test examples has an unique question content and its corresponded ground truth answers can be muliple. For each test example for inference, which includes one context and question, the model will output a predicted answer. Next. we will compare the predicted answer with each of the ground truth answers and use the best comparision result for model performance on that example. Details are shown in the inference section as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67454860-2cb1-400f-b133-b67e22d3dd8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_test_examples = {}\n",
    "\n",
    "for idx, row in test_data.iterrows():\n",
    "    if row[0] not in unique_test_examples:\n",
    "        unique_test_examples[row[0]] = {\n",
    "            \"context\": row[1],\n",
    "            \"answer\": [row[1][row[2]: row[3]]]\n",
    "        }\n",
    "    else:\n",
    "        assert row[1] == unique_test_examples[row[0]][\"context\"]\n",
    "        unique_test_examples[row[0]][\"answer\"].append(row[1][row[2]: row[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e1e4874-68e0-46a0-9063-f7574176641f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_examples = []\n",
    "ground_truth = []\n",
    "for key in unique_test_examples:\n",
    "    test_examples.append([key, unique_test_examples[key][\"context\"]])\n",
    "    ground_truth.append(unique_test_examples[key][\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52658a-2d4b-4974-8060-c9340dc76232",
   "metadata": {},
   "source": [
    "### 3.4. Fine-tuning without hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32994a3f-4243-4581-bc67-c7ebade7d571",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-soln-documents-js-ewrtgp-eqa--2023-06-28-02-51-35-109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-28 02:51:35 Starting - Starting the training job...\n",
      "2023-06-28 02:51:51 Starting - Preparing the instances for training......\n",
      "2023-06-28 02:52:57 Downloading - Downloading input data...\n",
      "2023-06-28 02:53:32 Training - Downloading the training image............\n",
      "2023-06-28 02:55:18 Training - Training image download completed. Training in progress.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-06-28 02:55:55,954 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-06-28 02:55:55,982 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-06-28 02:55:55,984 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-06-28 02:55:56,251 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"adam-learning-rate\": \"2e-05\",\n",
      "        \"batch-size\": \"16\",\n",
      "        \"epochs\": \"3\",\n",
      "        \"reinitialize-top-layer\": \"Auto\",\n",
      "        \"train-only-top-layer\": \"False\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-soln-documents-js-ewrtgp-eqa--2023-06-28-02-51-35-109\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/huggingface/transfer_learning/eqa/v1.0.2/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"adam-learning-rate\":\"2e-05\",\"batch-size\":\"16\",\"epochs\":\"3\",\"reinitialize-top-layer\":\"Auto\",\"train-only-top-layer\":\"False\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=transfer_learning.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"model\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=transfer_learning\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/huggingface/transfer_learning/eqa/v1.0.2/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"adam-learning-rate\":\"2e-05\",\"batch-size\":\"16\",\"epochs\":\"3\",\"reinitialize-top-layer\":\"Auto\",\"train-only-top-layer\":\"False\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-soln-documents-js-ewrtgp-eqa--2023-06-28-02-51-35-109\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/huggingface/transfer_learning/eqa/v1.0.2/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--adam-learning-rate\",\"2e-05\",\"--batch-size\",\"16\",\"--epochs\",\"3\",\"--reinitialize-top-layer\",\"Auto\",\"--train-only-top-layer\",\"False\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_ADAM-LEARNING-RATE=2e-05\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_REINITIALIZE-TOP-LAYER=Auto\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN-ONLY-TOP-LAYER=False\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 transfer_learning.py --adam-learning-rate 2e-05 --batch-size 16 --epochs 3 --reinitialize-top-layer Auto --train-only-top-layer False\u001b[0m\n",
      "\u001b[34mUsing custom data configuration default-2f986434076890f0\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-2f986434076890f0/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\u001b[0m\n",
      "\u001b[34mDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-2f986434076890f0/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m loaded train_dataset sizes is: 679\n",
      " loaded eval_dataset sizes is: 170\u001b[0m\n",
      "\u001b[34m[2023-06-28 02:56:05.280 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-06-28 02:56:05.331 algo-1:27 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m{'loss': 6.395, 'learning_rate': 1.9844961240310078e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 3.764836549758911, 'eval_runtime': 5.0474, 'eval_samples_per_second': 33.681, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m{'loss': 4.6333, 'learning_rate': 1.2248062015503876e-05, 'epoch': 1.16}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 3.0814266204833984, 'eval_runtime': 5.0556, 'eval_samples_per_second': 33.626, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m{'loss': 3.2591, 'learning_rate': 4.4961240310077525e-06, 'epoch': 2.33}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.839078426361084, 'eval_runtime': 5.0444, 'eval_samples_per_second': 33.701, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m{'train_runtime': 201.5449, 'train_samples_per_second': 0.64, 'epoch': 3.0}\u001b[0m\n",
      "\n",
      "2023-06-28 02:59:39 Uploading - Uploading generated training model\u001b[34m#0150 tables [00:00, ? tables/s]#015                            #015#015  0%|          | 0/1 [00:00<?, ?ba/s]#015100%|██████████| 1/1 [00:00<00:00,  2.37ba/s]#015100%|██████████| 1/1 [00:00<00:00,  2.36ba/s]\u001b[0m\n",
      "\u001b[34m2023-06-28 02:59:28,271 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-06-28 03:00:15 Completed - Training job completed\n",
      "Training seconds: 438\n",
      "Billable seconds: 438\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "training_job_name = training_job_name = f\"{config.SOLUTION_PREFIX}-eqa-finetune\"\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "eqa_estimator = Estimator(\n",
    "    role=role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    "    tags=[{'Key': config.TAG_KEY, 'Value': config.SOLUTION_PREFIX}],\n",
    "    base_job_name=training_job_name,\n",
    "    debugger_hook_config=False,\n",
    ")\n",
    "\n",
    "\n",
    "training_data_path_updated = f\"s3://{config.S3_BUCKET}/{prefix}/train\"\n",
    "# Launch a SageMaker Training job by passing s3 path of the training data\n",
    "eqa_estimator.fit({\"training\": training_data_path_updated}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9245d057-9a65-40e8-8484-de03e357cab6",
   "metadata": {},
   "source": [
    "## 3.5. Deploy & run Inference on the fine-tuned model\n",
    "\n",
    "A trained model does nothing on its own. We now want to use the model to perform inference. For this example, that means predicting the answer of an input sentence including a context and question. We follow the same steps as in `2. Run inference on the pre-trained extractive question answering model`. We start by retrieving the jumpstart artifacts for deploying an endpoint. However, instead of base_predictor, we  deploy the `eqa_estimator` that we fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacfaa36-0e3b-43c8-ba76-10a8c24b00ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_instance_type = config.HOSTING_INSTANCE_TYPE\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "# Retrieve the inference script uri\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "endpoint_name_finetune = f\"{config.SOLUTION_PREFIX}-eqa-finetune-endpoint-1\"\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "finetuned_predictor = eqa_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name_finetune,\n",
    ")\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "268690f5-aa1a-4fd8-affe-27c9fa1ded84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
    "\n",
    "\n",
    "def query_endpoint(encoded_text, predictor):\n",
    "    response = predictor.predict(\n",
    "        encoded_text, {\"ContentType\": \"application/list-text\", \"Accept\": \"application/json;verbose\"}\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response)\n",
    "    answer = (model_predictions[\"answer\"],)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebc3bb9e-3b4c-4309-8577-561f640af83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for question_context in test_examples:\n",
    "    query_response = query_endpoint(json.dumps(question_context).encode(\"utf-8\"), finetuned_predictor)\n",
    "    answer = parse_response(query_response)\n",
    "    predictions.append(answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7c6c2a8-3c4e-4eea-82ac-57d29bd45025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# these functions are heavily influenced by the HF squad_metrics.py script\n",
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b25bdda8-68b4-413b-854f-427de28a5ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Exact Matching score: 0.29133858267716534\n",
      "Average F1 score: 0.42883719517577784\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "em_score, f1_score = [], []\n",
    "\n",
    "for prediction, gold_answers in zip(predictions, ground_truth):\n",
    "    em_score.append(\n",
    "        max((compute_exact_match(prediction, answer)) for answer in gold_answers)\n",
    "    )\n",
    "    f1_score.append(\n",
    "        max((compute_f1(prediction, answer)) for answer in gold_answers)\n",
    "    )\n",
    "    \n",
    "print(f\"Average Exact Matching score: {np.mean(em_score)}\")    \n",
    "print(f\"Average F1 score: {np.mean(f1_score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b7876a1-9b53-411e-b752-4fa9c26c6d48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = {\"Average Exact Matching score\": [np.mean(em_score)], \"Average F1 Score\": [np.mean(f1_score)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25869fd5-4fb5-49aa-b214-2649cea0af52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame.from_dict(result, orient='index', columns=[\"No HPO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d891f5cb-41fb-4830-a2d7-80e07f12a28c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No HPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average Exact Matching score</th>\n",
       "      <td>0.291339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average F1 Score</th>\n",
       "      <td>0.428837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                No HPO\n",
       "Average Exact Matching score  0.291339\n",
       "Average F1 Score              0.428837"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827b788-3e50-4e57-941c-41620a88a533",
   "metadata": {},
   "source": [
    "## 4. Finetune the pre-trained model on a custom dataset with automatic model tuning (AMT)\n",
    "\n",
    "Amazon SageMaker automatic model tuning, also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose. We will use a [HyperparameterTuner](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html) object to interact with Amazon SageMaker hyperparameter tuning APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0026d7a3-414b-4efb-8f91-37a00185e4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter, IntegerParameter, CategoricalParameter, HyperparameterTuner\n",
    "\n",
    "\n",
    "# Define objective metric per framework, based on which the best model will be selected.\n",
    "# metric_definitions_per_model = {\n",
    "#     \"pytorch\": {\n",
    "#         \"metrics\": [{\"Name\": \"validation:loss\", \"Regex\": \"val_loss: ([0-9\\\\.]+)\"}],\n",
    "#         \"type\": \"Minimize\",\n",
    "#     }\n",
    "# }\n",
    "\n",
    "metric_definitions_per_model = {\n",
    "    \"pytorch\": {\n",
    "        \"metrics\": [\n",
    "            {\"Name\": \"loss\", \"Regex\": \"'loss': ([0-9\\\\.]+)\"},\n",
    "            {\"Name\": \"eval_loss\", \"Regex\": \"'eval_loss': ([0-9\\\\.]+)\"}\n",
    "        ],\n",
    "        \"type\": \"Minimize\",\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# metric_definitions = [\n",
    "#      {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9.]+)'},\n",
    "#      {'Name': 'validation:accuracy', 'Regex': 'val_acc: ([0-9.]+)'},\n",
    "# ]\n",
    "\n",
    "# You can select from the hyperparameters supported by the model, and configure ranges of values to be searched for training the optimal model.(https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html)\n",
    "hyperparameter_ranges = {\n",
    "    \"adam-learning-rate\": ContinuousParameter(0.00001, 0.01, scaling_type=\"Logarithmic\"),\n",
    "    \"epochs\": IntegerParameter(3, 10),\n",
    "    \"train-only-top-layer\": CategoricalParameter([\"True\", \"False\"]),\n",
    "}\n",
    "\n",
    "# Increase the total number of training jobs run by AMT, for increased accuracy (and training time).\n",
    "max_jobs = 1\n",
    "# Change parallel training jobs run by AMT to reduce total training time, constrained by your account limits.\n",
    "# if max_jobs=max_parallel_jobs then Bayesian search turns to Random.\n",
    "max_parallel_jobs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed47cb-310e-4a82-a97d-6f575f0ced8c",
   "metadata": {},
   "source": [
    "### 4.1. Fine-tuning with hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c88dcb6-39ee-4e77-956c-d6aa585886e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: sagemaker-soln-docum-230628-0452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "tuning_job_name = f\"{config.SOLUTION_PREFIX}-eqa-hpo-1\"\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "eqa_estimator = Estimator(\n",
    "    role=role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    "    tags=[{'Key': config.TAG_KEY, 'Value': config.SOLUTION_PREFIX}],\n",
    "    base_job_name=tuning_job_name,\n",
    "    debugger_hook_config=False,\n",
    ")\n",
    "\n",
    "model_id = \"pytorch-model-123\"\n",
    "\n",
    "metric_definitions = next(\n",
    "    value for key, value in metric_definitions_per_model.items() if model_id.startswith(key)\n",
    ")\n",
    "\n",
    "# metric_definitions = next(\n",
    "#     (value for key, value in metric_definitions_per_model.items() if model_id.startswith(key)), \n",
    "#     None\n",
    "# )\n",
    "\n",
    "\n",
    "hp_tuner = HyperparameterTuner(\n",
    "    eqa_estimator,\n",
    "    metric_definitions[\"metrics\"][0][\"Name\"],\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions[\"metrics\"],\n",
    "    max_jobs=max_jobs,\n",
    "    max_parallel_jobs=max_parallel_jobs,\n",
    "    objective_type=metric_definitions[\"type\"],\n",
    "    base_tuning_job_name=training_job_name,\n",
    ")\n",
    "\n",
    "# Launch a SageMaker Tuning job to search for the best hyperparameters\n",
    "hp_tuner.fit({\"training\": training_data_path_updated})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee6f46-1452-45fc-a275-680a39a40c9a",
   "metadata": {},
   "source": [
    "### 4.2. Deploy & run Inference on the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f296db-887a-464f-a79b-4b3c88d16eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the inference docker container uri\n",
    "model_id = \"huggingface-eqa-bert-base-uncased\" \n",
    "\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "# Retrieve the inference script uri\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "endpoint_name_hpo = f\"{config.SOLUTION_PREFIX}-eqa-hpo-endpoint\"\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "finetuned_predictor_hpo = hp_tuner.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name_hpo,\n",
    ")\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4cd65ba5-0182-435a-a85c-40718d414d81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_hpo = []\n",
    "for question_context in test_examples:\n",
    "    query_response = query_endpoint(json.dumps(question_context).encode(\"utf-8\"), finetuned_predictor_hpo)\n",
    "    answer = parse_response(query_response)\n",
    "    predictions_hpo.append(answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1a5414f6-8dfe-4414-b232-6ed71e90ccd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Exact Matching score: 0.5354330708661418\n",
      "Average F1 score: 0.723536437315965\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "em_score_hpo, f1_score_hpo = [], []\n",
    "\n",
    "for prediction, gold_answers in zip(predictions_hpo, ground_truth):\n",
    "    em_score_hpo.append(\n",
    "        max((compute_exact_match(prediction, answer)) for answer in gold_answers)\n",
    "    )\n",
    "    f1_score_hpo.append(\n",
    "        max((compute_f1(prediction, answer)) for answer in gold_answers)\n",
    "    )\n",
    "    \n",
    "print(f\"Average Exact Matching score: {np.mean(em_score_hpo)}\")    \n",
    "print(f\"Average F1 score: {np.mean(f1_score_hpo)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a086e2e5-e860-4101-9040-77dd9aadc126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_hpo = {\"Average Exact Matching score\": [np.mean(em_score_hpo)], \"Average F1 Score\": [np.mean(f1_score_hpo)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7bbb35c5-db89-4cbe-9d30-9427fc708c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_hpo = pd.DataFrame.from_dict(result_hpo, orient='index', columns=[\"With HPO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bdefc5f9-841a-4a48-9cef-cd67328fccfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No HPO</th>\n",
       "      <th>With HPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average Exact Matching score</th>\n",
       "      <td>0.291339</td>\n",
       "      <td>0.535433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average F1 Score</th>\n",
       "      <td>0.428837</td>\n",
       "      <td>0.723536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                No HPO  With HPO\n",
       "Average Exact Matching score  0.291339  0.535433\n",
       "Average F1 Score              0.428837  0.723536"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([result, result_hpo], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7119cb5c-d4d2-4014-8dac-74c8e1d4d59e",
   "metadata": {},
   "source": [
    "We can see results with hyperparameter optimization shows better performance on the hold-out test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a51f4c-5461-406a-88d4-c4d9041b0f0b",
   "metadata": {},
   "source": [
    "## 4.3. Clean Up the endpoint\n",
    "\n",
    "When you've finished with the summarization endpoint (and associated\n",
    "endpoint-config), make sure that you delete it to avoid accidental\n",
    "charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f4b8861-ab59-42f8-9bd2-031808027b12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: sagemaker-jumpstart-2023-06-28-03-09-45-131\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: sagemaker-soln-documents-js-ewrtgp-eqa-finetune-endpoint-1\n",
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-soln-documents-js-ewrtgp-eqa-finetune-endpoint-1\n",
      "INFO:sagemaker:Deleting model with name: sagemaker-jumpstart-2023-06-28-05-19-03-153\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: sagemaker-soln-documents-js-ewrtgp-eqa-hpo-endpoint\n",
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-soln-documents-js-ewrtgp-eqa-hpo-endpoint\n"
     ]
    }
   ],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "finetuned_predictor.delete_model()\n",
    "finetuned_predictor.delete_endpoint()\n",
    "\n",
    "finetuned_predictor_hpo.delete_model()\n",
    "finetuned_predictor_hpo.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf4895",
   "metadata": {},
   "source": [
    "## Next Stage\n",
    "\n",
    "We've just looked at how you can query document for specific information.\n",
    "Up next we'll look at a technique that can be used to extract the key\n",
    "entities from a document, called Entity Recognition.\n",
    "\n",
    "[Click here to continue with Name Entity Recognition.](./4_entity_recognition.ipynb)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
